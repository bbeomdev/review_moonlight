{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "G-i7tu_EaXdx"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "T_QItMa32l1x"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zI32Nhu9gysM"
   },
   "source": [
    "1. encoder 제거\n",
    "2. positional embedding을 학습가능한 embedding 층으로 대체\n",
    "3. decoder block에 masked self attention만 수행\n",
    "4. 기존의 addnorm, dense 구조 유지\n",
    "5. loss 함수에서 context 부분과 padding 부분은 loss에 포함시키지 않도록 수정\n",
    "6. weight tying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xpPgU5ISeJNe"
   },
   "source": [
    "#1.기본gpt구조"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L5rm7ve4eO4F"
   },
   "source": [
    "##1.1재료"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8XnxfEXYab35",
    "outputId": "87598012-128a-405b-c7a0-8f0142d5ca8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 스케일드 닷 프로덕트 어텐션 함수\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "  # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
    "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "  # 가중치를 정규화\n",
    "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "  logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "  # 패딩에 마스크 추가\n",
    "  if mask is not None:\n",
    "    logits += (mask * -1e9)\n",
    "\n",
    "  # softmax적용\n",
    "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "  # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
    "  output = tf.matmul(attention_weights, value)\n",
    "  return output\n",
    "\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "njdpY5iweY7W",
    "outputId": "68a2cce5-38af-4d05-d957-a3c2f39adb81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, kernel_initializer='glorot_uniform', name=\"multi_head_attention\"):\n",
    "    super(MultiHeadAttention, self).__init__(name=name)\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "    self.kernel_initializer = tf.keras.initializers.get(kernel_initializer)\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    self.query_dense = tf.keras.layers.Dense(units=d_model,kernel_initializer=self.kernel_initializer)\n",
    "    self.key_dense = tf.keras.layers.Dense(units=d_model,kernel_initializer=self.kernel_initializer)\n",
    "    self.value_dense = tf.keras.layers.Dense(units=d_model,kernel_initializer=self.kernel_initializer)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(units=d_model,kernel_initializer=self.kernel_initializer)\n",
    "\n",
    "  def split_heads(self, inputs, batch_size):\n",
    "    inputs = tf.reshape(\n",
    "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, inputs):\n",
    "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "        'value'], inputs['mask']\n",
    "    batch_size = tf.shape(query)[0]\n",
    "\n",
    "    # Q, K, V에 각각 Dense를 적용합니다\n",
    "    query = self.query_dense(query)\n",
    "    key = self.key_dense(key)\n",
    "    value = self.value_dense(value)\n",
    "\n",
    "    # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
    "    query = self.split_heads(query,batch_size)\n",
    "    key = self.split_heads(key,batch_size)\n",
    "    value = self.split_heads(value,batch_size)\n",
    "\n",
    "    # 스케일드 닷 프로덕트 어텐션 함수\n",
    "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "    # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
    "    concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "\n",
    "    # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
    "    outputs = self.dense(concat_attention)\n",
    "\n",
    "    return outputs\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KM7pVnDwedDW",
    "outputId": "b025d597-d2e5-447e-9b22-7a5103248677"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def create_padding_mask(x):\n",
    "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "  # (batch_size, 1, 1, sequence length)\n",
    "  return mask[:, tf.newaxis, tf.newaxis, :]\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tf5ATmeVefIy",
    "outputId": "20e8f865-db10-430e-8dba-98fb250de806"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "  seq_len = tf.shape(x)[1]\n",
    "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "  padding_mask = create_padding_mask(x)\n",
    "  return tf.maximum(look_ahead_mask, padding_mask)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NGyNzXMFesvl"
   },
   "source": [
    "#1.2decoder-only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "GjApZUmQf14N"
   },
   "outputs": [],
   "source": [
    "def position_gen(inputs):\n",
    "  batch_size=tf.shape(inputs)[0]\n",
    "  seq_len=tf.shape(inputs)[1]\n",
    "  positions = tf.range(start=0, limit=seq_len, delta=1)\n",
    "  positions = tf.expand_dims(positions, 0)\n",
    "  positions = tf.tile(positions, [batch_size, 1])\n",
    "  return positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vj32h05Eeo4V",
    "outputId": "f8000d41-1841-4651-cacf-fc08447e01a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 디코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
    "def decoder_layeraa(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "\n",
    "  initializer = tf.keras.initializers.GlorotUniform(seed=42)\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention1 = MultiHeadAttention(\n",
    "      d_model, num_heads, kernel_initializer=initializer, name=\"attention_1\")(inputs={\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': look_ahead_mask\n",
    "      })\n",
    "\n",
    "  # 마스크드 멀티 헤드 어텐션의 결과는\n",
    "  # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention1 = tf.keras.layers.Dropout(rate=dropout)(attention1)\n",
    "  attention2 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "  # 세 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu',kernel_initializer=initializer)(attention2)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model,kernel_initializer=initializer)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "##encoder부분 다 들어내고 decoder 흐름이 잘 연결되도록 마스크랑 구성\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, look_ahead_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xvMB0Tlter5B",
    "outputId": "d9adedce-6078-4258-f61b-767dfb583e8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def decoderaa(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            max_len,\n",
    "            name='decoder'):\n",
    "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name='look_ahead_mask')\n",
    "  initializer = tf.keras.initializers.GlorotUniform(seed=42)\n",
    "  # 임베딩 레이어\n",
    "  embedding_layer = tf.keras.layers.Embedding(vocab_size, d_model,embeddings_initializer=initializer)\n",
    "  embeddings=embedding_layer(inputs)\n",
    "  #embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  positions = tf.keras.Input(shape=(None,), name='positions')\n",
    "  position_embeddings = tf.keras.layers.Embedding(max_len, d_model,embeddings_initializer=initializer)(positions)\n",
    "\n",
    "  embeddings += position_embeddings\n",
    "\n",
    "  # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  for i in range(num_layers):\n",
    "    outputs = decoder_layeraa(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name='decoder_layer_{}'.format(i),\n",
    "    )(inputs=[outputs, look_ahead_mask])\n",
    "\n",
    "  embedding_weights = embedding_layer.weights[0]\n",
    "  outputs = tf.keras.layers.Lambda(lambda x: tf.matmul(x[0],x[1],transpose_b=True),output_shape=(None,vocab_size))([outputs,embedding_weights])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, positions,look_ahead_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w6UUx2Puh_5e"
   },
   "source": [
    "#2.데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "dfCXtEXEiLRu"
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv('ChatbotData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "43Kx77fLiPi7",
    "outputId": "81a56f1a-fdf1-4a87-90ae-15da50836254"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "  sentence = re.sub(r\"([?!,])\", r\" \\1 \", sentence).lower()\n",
    "\n",
    "  sentence = re.sub(r'[^가-힣a-zA-Z0-9.,?!\\s]', ' ', sentence)\n",
    "  sentence = re.sub(r'\\s+', \" \", sentence)\n",
    "  sentence = re.sub(r'^\\s+|\\s+$', '', sentence)\n",
    "\n",
    "  return sentence\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "NTlcgrQpiT8f"
   },
   "outputs": [],
   "source": [
    "data['A_']=data['A'].apply(preprocess_sentence)\n",
    "data['Q_']=data['Q'].apply(preprocess_sentence)\n",
    "\n",
    "inputs=np.array(data['Q_'])\n",
    "outputs=np.array(data['A_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "49As7UEMiXtA",
    "outputId": "d7153c56-c60d-406e-d33c-8f5c4349df67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "살짝 오래 걸릴 수 있어요. 스트레칭 한 번 해볼까요? 👐\n",
      "슝=3 \n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "print(\"살짝 오래 걸릴 수 있어요. 스트레칭 한 번 해볼까요? 👐\")\n",
    "\n",
    "# 질문과 답변 데이터셋에 대해서 Vocabulary 생성\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(inputs + outputs, target_vocab_size=2**14)\n",
    "print(\"슝=3 \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uiXii_qai3jh",
    "outputId": "99dd1e44-755d-421e-b407-2d1fd078d4e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.593504186754631\n"
     ]
    }
   ],
   "source": [
    "lens=[]\n",
    "for i in range(len(inputs)):\n",
    "  lens.append(len(tokenizer.encode(outputs[i])))\n",
    "\n",
    "print(np.array(lens).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "nTfXmTX8jwyz",
    "outputId": "6be9f6c4-c75a-451f-f7c5-e746b9777659"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Density'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.kdeplot(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "J-eNoOldj5Ja"
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 17\n",
    "VOCAB_SIZE = tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "WWotY26kj8eU"
   },
   "outputs": [],
   "source": [
    "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "  tokenized_inputs, tokenized_outputs = [], []\n",
    "  decoder_inputs=[]\n",
    "\n",
    "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "    sentence1 = tokenizer.encode(sentence1)\n",
    "    sentence2 = tokenizer.encode(sentence2)\n",
    "\n",
    "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "      tokenized_inputs.append(sentence1)\n",
    "      tokenized_outputs.append(sentence2)\n",
    "\n",
    "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "\n",
    "  for (sentence1, sentence2) in zip(tokenized_inputs, tokenized_outputs):\n",
    "    combined = np.concatenate([sentence1, sentence2], axis=0)\n",
    "    decoder_inputs.append(combined)\n",
    "\n",
    "  return np.array(decoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9OJ-3E2qj_l8",
    "outputId": "2d0717db-1887-4dc6-92dc-5156f38be074"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 10457\n",
      "필터링 후의 질문 샘플 개수: 11788\n"
     ]
    }
   ],
   "source": [
    "decoder_inputs = tokenize_and_filter(inputs, outputs)\n",
    "print('단어장의 크기 :',(VOCAB_SIZE))\n",
    "print('필터링 후의 질문 샘플 개수: {}'.format(len(decoder_inputs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OUPw7bzskBam",
    "outputId": "06aa24a1-21c7-4c73-faa3-3df1f8fa5926"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "SEED = 42\n",
    "\n",
    "\n",
    "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
    "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'dec_inputs': decoder_inputs[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'decoder': decoder_inputs[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "total_size=len(dataset)\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE, seed=SEED)\n",
    "\n",
    "train_size = int(0.8 * total_size)\n",
    "train_dataset = dataset.take(train_size)\n",
    "val_dataset = dataset.skip(train_size)\n",
    "\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EtHeb5NCh6h_"
   },
   "source": [
    "#3.model 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dkVSJTerh9wu",
    "outputId": "aa1d2d3c-6900-493a-8c43-5e77f9cfd6e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def transformeraa(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                max_len,\n",
    "                name=\"transformer\"):\n",
    "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "  # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
    "  # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "  look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_look_ahead_mask,\n",
    "      output_shape=(1, None, None),\n",
    "      name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "  positions=tf.keras.layers.Lambda(\n",
    "      position_gen,\n",
    "      output_shape=(None,d_model),\n",
    "      name='positions')(dec_inputs)\n",
    "\n",
    "  # 디코더\n",
    "  dec_outputs = decoderaa(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "      max_len=max_len\n",
    "  )(inputs=[dec_inputs, positions, look_ahead_mask])\n",
    "\n",
    "  # 완전연결층\n",
    "  #outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "  return tf.keras.Model(inputs=dec_inputs, outputs=dec_outputs, name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "id": "2AQ4eUfxmV1X",
    "outputId": "fbe2724b-a572-4267-9f75-246606351c5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (lambda), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'embedding/embeddings:0' shape=(10457, 256) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (lambda), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'embedding/embeddings:0' shape=(10457, 256) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "positions (Lambda)              (None, None)         0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 10457)  4793856     dec_inputs[0][0]                 \n",
      "                                                                 positions[0][0]                  \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 4,793,856\n",
      "Trainable params: 4,793,856\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 4 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수\n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.2 # 드롭아웃의 비율\n",
    "\n",
    "model = transformeraa(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT,\n",
    "    max_len=MAX_LENGTH*2-1)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TSIitn2zspJR"
   },
   "source": [
    "#4.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eDmm1frJsoVy",
    "outputId": "2306b2b1-078b-42a4-efcd-f61741acc208"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH*2 - 1))\n",
    "\n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction='none')(y_true, y_pred)\n",
    "  front_mask = tf.concat([\n",
    "      tf.zeros((tf.shape(y_true)[0], 16)),\n",
    "      tf.ones((tf.shape(y_true)[0], tf.shape(y_true)[1] - 16))\n",
    "  ], axis=1)\n",
    "\n",
    "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "  final_mask = mask * front_mask\n",
    "  loss = tf.multiply(loss, final_mask)\n",
    "\n",
    "  return tf.reduce_mean(loss)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4c86tBABssST",
    "outputId": "6a12e67e-9723-4ba9-90df-b98cdebae790"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "M-vrwTU9suVp"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rUgV5g9Rswmp",
    "outputId": "041b3307-a960-463c-e090-27bfc87b704c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH*2 - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "id": "8KVLXvcYs-yQ",
    "outputId": "5d04a466-24c8-4a81-ca44-a92b693ff6d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "148/148 [==============================] - 15s 70ms/step - loss: 1.5053 - accuracy: 0.0202 - val_loss: 1.4292 - val_accuracy: 0.0344\n",
      "Epoch 2/200\n",
      "148/148 [==============================] - 9s 64ms/step - loss: 1.3405 - accuracy: 0.0344 - val_loss: 1.2285 - val_accuracy: 0.0342\n",
      "Epoch 3/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 1.1950 - accuracy: 0.0346 - val_loss: 1.1523 - val_accuracy: 0.0344\n",
      "Epoch 4/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 1.1475 - accuracy: 0.0324 - val_loss: 1.1175 - val_accuracy: 0.0296\n",
      "Epoch 5/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 1.1237 - accuracy: 0.0299 - val_loss: 1.0959 - val_accuracy: 0.0296\n",
      "Epoch 6/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 1.0804 - accuracy: 0.0308 - val_loss: 1.0402 - val_accuracy: 0.0324\n",
      "Epoch 7/200\n",
      "148/148 [==============================] - 10s 64ms/step - loss: 1.0472 - accuracy: 0.0328 - val_loss: 0.9963 - val_accuracy: 0.0346\n",
      "Epoch 8/200\n",
      "148/148 [==============================] - 9s 64ms/step - loss: 1.0174 - accuracy: 0.0342 - val_loss: 0.9631 - val_accuracy: 0.0359\n",
      "Epoch 9/200\n",
      "148/148 [==============================] - 9s 64ms/step - loss: 0.9940 - accuracy: 0.0356 - val_loss: 0.9374 - val_accuracy: 0.0365\n",
      "Epoch 10/200\n",
      "148/148 [==============================] - 9s 64ms/step - loss: 0.9682 - accuracy: 0.0369 - val_loss: 0.9191 - val_accuracy: 0.0386\n",
      "Epoch 11/200\n",
      "148/148 [==============================] - 10s 64ms/step - loss: 0.9423 - accuracy: 0.0384 - val_loss: 0.9010 - val_accuracy: 0.0413\n",
      "Epoch 12/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.9104 - accuracy: 0.0401 - val_loss: 0.8518 - val_accuracy: 0.0431\n",
      "Epoch 13/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.8836 - accuracy: 0.0416 - val_loss: 0.8068 - val_accuracy: 0.0456\n",
      "Epoch 14/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.8466 - accuracy: 0.0438 - val_loss: 0.7785 - val_accuracy: 0.0474\n",
      "Epoch 15/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.8164 - accuracy: 0.0458 - val_loss: 0.7293 - val_accuracy: 0.0512\n",
      "Epoch 16/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.7748 - accuracy: 0.0495 - val_loss: 0.6808 - val_accuracy: 0.0575\n",
      "Epoch 17/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.7328 - accuracy: 0.0532 - val_loss: 0.6319 - val_accuracy: 0.0629\n",
      "Epoch 18/200\n",
      "148/148 [==============================] - 10s 64ms/step - loss: 0.6897 - accuracy: 0.0575 - val_loss: 0.5748 - val_accuracy: 0.0694\n",
      "Epoch 19/200\n",
      "148/148 [==============================] - 9s 64ms/step - loss: 0.6437 - accuracy: 0.0622 - val_loss: 0.5334 - val_accuracy: 0.0756\n",
      "Epoch 20/200\n",
      "148/148 [==============================] - 10s 64ms/step - loss: 0.5998 - accuracy: 0.0673 - val_loss: 0.4753 - val_accuracy: 0.0825\n",
      "Epoch 21/200\n",
      "148/148 [==============================] - 10s 64ms/step - loss: 0.5576 - accuracy: 0.0721 - val_loss: 0.4299 - val_accuracy: 0.0914\n",
      "Epoch 22/200\n",
      "148/148 [==============================] - 10s 64ms/step - loss: 0.5150 - accuracy: 0.0773 - val_loss: 0.3711 - val_accuracy: 0.1015\n",
      "Epoch 23/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.4761 - accuracy: 0.0834 - val_loss: 0.3291 - val_accuracy: 0.1045\n",
      "Epoch 24/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.4312 - accuracy: 0.0892 - val_loss: 0.2831 - val_accuracy: 0.1150\n",
      "Epoch 25/200\n",
      "148/148 [==============================] - 10s 64ms/step - loss: 0.3953 - accuracy: 0.0932 - val_loss: 0.2533 - val_accuracy: 0.1182\n",
      "Epoch 26/200\n",
      "148/148 [==============================] - 10s 64ms/step - loss: 0.3655 - accuracy: 0.0981 - val_loss: 0.2085 - val_accuracy: 0.1262\n",
      "Epoch 27/200\n",
      "148/148 [==============================] - 9s 64ms/step - loss: 0.3312 - accuracy: 0.1027 - val_loss: 0.1818 - val_accuracy: 0.1291\n",
      "Epoch 28/200\n",
      "148/148 [==============================] - 10s 64ms/step - loss: 0.3021 - accuracy: 0.1068 - val_loss: 0.1579 - val_accuracy: 0.1364\n",
      "Epoch 29/200\n",
      "148/148 [==============================] - 10s 64ms/step - loss: 0.2696 - accuracy: 0.1114 - val_loss: 0.1275 - val_accuracy: 0.1418\n",
      "Epoch 30/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.2451 - accuracy: 0.1170 - val_loss: 0.1061 - val_accuracy: 0.1462\n",
      "Epoch 31/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.2176 - accuracy: 0.1209 - val_loss: 0.0859 - val_accuracy: 0.1499\n",
      "Epoch 32/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.1951 - accuracy: 0.1245 - val_loss: 0.0748 - val_accuracy: 0.1529\n",
      "Epoch 33/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.1767 - accuracy: 0.1286 - val_loss: 0.0611 - val_accuracy: 0.1550\n",
      "Epoch 34/200\n",
      "148/148 [==============================] - 10s 64ms/step - loss: 0.1603 - accuracy: 0.1316 - val_loss: 0.0497 - val_accuracy: 0.1563\n",
      "Epoch 35/200\n",
      "148/148 [==============================] - 10s 64ms/step - loss: 0.1456 - accuracy: 0.1347 - val_loss: 0.0424 - val_accuracy: 0.1592\n",
      "Epoch 36/200\n",
      "148/148 [==============================] - 10s 64ms/step - loss: 0.1320 - accuracy: 0.1376 - val_loss: 0.0383 - val_accuracy: 0.1601\n",
      "Epoch 37/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.1208 - accuracy: 0.1395 - val_loss: 0.0314 - val_accuracy: 0.1642\n",
      "Epoch 38/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.1114 - accuracy: 0.1419 - val_loss: 0.0263 - val_accuracy: 0.1633\n",
      "Epoch 39/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.1034 - accuracy: 0.1440 - val_loss: 0.0236 - val_accuracy: 0.1649\n",
      "Epoch 40/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0967 - accuracy: 0.1453 - val_loss: 0.0209 - val_accuracy: 0.1645\n",
      "Epoch 41/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0908 - accuracy: 0.1466 - val_loss: 0.0182 - val_accuracy: 0.1630\n",
      "Epoch 42/200\n",
      "148/148 [==============================] - 10s 64ms/step - loss: 0.0836 - accuracy: 0.1475 - val_loss: 0.0168 - val_accuracy: 0.1641\n",
      "Epoch 43/200\n",
      "148/148 [==============================] - 10s 64ms/step - loss: 0.0788 - accuracy: 0.1494 - val_loss: 0.0157 - val_accuracy: 0.1667\n",
      "Epoch 44/200\n",
      "148/148 [==============================] - 9s 64ms/step - loss: 0.0762 - accuracy: 0.1499 - val_loss: 0.0131 - val_accuracy: 0.1665\n",
      "Epoch 45/200\n",
      "148/148 [==============================] - 10s 64ms/step - loss: 0.0709 - accuracy: 0.1511 - val_loss: 0.0115 - val_accuracy: 0.1653\n",
      "Epoch 46/200\n",
      "148/148 [==============================] - 10s 64ms/step - loss: 0.0668 - accuracy: 0.1523 - val_loss: 0.0114 - val_accuracy: 0.1671\n",
      "Epoch 47/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0641 - accuracy: 0.1529 - val_loss: 0.0102 - val_accuracy: 0.1652\n",
      "Epoch 48/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0620 - accuracy: 0.1527 - val_loss: 0.0090 - val_accuracy: 0.1655\n",
      "Epoch 49/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0592 - accuracy: 0.1542 - val_loss: 0.0086 - val_accuracy: 0.1684\n",
      "Epoch 50/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0575 - accuracy: 0.1544 - val_loss: 0.0084 - val_accuracy: 0.1678\n",
      "Epoch 51/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0536 - accuracy: 0.1560 - val_loss: 0.0072 - val_accuracy: 0.1661\n",
      "Epoch 52/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0527 - accuracy: 0.1562 - val_loss: 0.0075 - val_accuracy: 0.1667\n",
      "Epoch 53/200\n",
      "148/148 [==============================] - 9s 64ms/step - loss: 0.0509 - accuracy: 0.1555 - val_loss: 0.0065 - val_accuracy: 0.1671\n",
      "Epoch 54/200\n",
      "148/148 [==============================] - 10s 64ms/step - loss: 0.0488 - accuracy: 0.1563 - val_loss: 0.0069 - val_accuracy: 0.1673\n",
      "Epoch 55/200\n",
      "148/148 [==============================] - 10s 64ms/step - loss: 0.0457 - accuracy: 0.1574 - val_loss: 0.0064 - val_accuracy: 0.1689\n",
      "Epoch 56/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0448 - accuracy: 0.1579 - val_loss: 0.0059 - val_accuracy: 0.1681\n",
      "Epoch 57/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0435 - accuracy: 0.1580 - val_loss: 0.0054 - val_accuracy: 0.1662\n",
      "Epoch 58/200\n",
      "148/148 [==============================] - 10s 64ms/step - loss: 0.0418 - accuracy: 0.1589 - val_loss: 0.0051 - val_accuracy: 0.1680\n",
      "Epoch 59/200\n",
      "148/148 [==============================] - 10s 64ms/step - loss: 0.0403 - accuracy: 0.1584 - val_loss: 0.0048 - val_accuracy: 0.1700\n",
      "Epoch 60/200\n",
      "148/148 [==============================] - 10s 64ms/step - loss: 0.0405 - accuracy: 0.1594 - val_loss: 0.0043 - val_accuracy: 0.1682\n",
      "Epoch 61/200\n",
      "148/148 [==============================] - 9s 64ms/step - loss: 0.0368 - accuracy: 0.1599 - val_loss: 0.0038 - val_accuracy: 0.1707\n",
      "Epoch 62/200\n",
      "148/148 [==============================] - 10s 64ms/step - loss: 0.0374 - accuracy: 0.1594 - val_loss: 0.0042 - val_accuracy: 0.1666\n",
      "Epoch 63/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0362 - accuracy: 0.1598 - val_loss: 0.0036 - val_accuracy: 0.1693\n",
      "Epoch 64/200\n",
      "148/148 [==============================] - 10s 64ms/step - loss: 0.0352 - accuracy: 0.1595 - val_loss: 0.0041 - val_accuracy: 0.1687\n",
      "Epoch 65/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0340 - accuracy: 0.1595 - val_loss: 0.0037 - val_accuracy: 0.1667\n",
      "Epoch 66/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0320 - accuracy: 0.1617 - val_loss: 0.0034 - val_accuracy: 0.1696\n",
      "Epoch 67/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0324 - accuracy: 0.1609 - val_loss: 0.0038 - val_accuracy: 0.1674\n",
      "Epoch 68/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0323 - accuracy: 0.1610 - val_loss: 0.0039 - val_accuracy: 0.1667\n",
      "Epoch 69/200\n",
      "148/148 [==============================] - 10s 64ms/step - loss: 0.0303 - accuracy: 0.1611 - val_loss: 0.0038 - val_accuracy: 0.1681\n",
      "Epoch 70/200\n",
      "148/148 [==============================] - 10s 64ms/step - loss: 0.0315 - accuracy: 0.1611 - val_loss: 0.0034 - val_accuracy: 0.1684\n",
      "Epoch 71/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0291 - accuracy: 0.1614 - val_loss: 0.0024 - val_accuracy: 0.1691\n",
      "Epoch 72/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0284 - accuracy: 0.1625 - val_loss: 0.0030 - val_accuracy: 0.1678\n",
      "Epoch 73/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0283 - accuracy: 0.1614 - val_loss: 0.0031 - val_accuracy: 0.1674\n",
      "Epoch 74/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0279 - accuracy: 0.1620 - val_loss: 0.0032 - val_accuracy: 0.1690\n",
      "Epoch 75/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0262 - accuracy: 0.1633 - val_loss: 0.0025 - val_accuracy: 0.1700\n",
      "Epoch 76/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0262 - accuracy: 0.1627 - val_loss: 0.0023 - val_accuracy: 0.1687\n",
      "Epoch 77/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0250 - accuracy: 0.1631 - val_loss: 0.0022 - val_accuracy: 0.1697\n",
      "Epoch 78/200\n",
      "148/148 [==============================] - 9s 64ms/step - loss: 0.0255 - accuracy: 0.1629 - val_loss: 0.0027 - val_accuracy: 0.1682\n",
      "Epoch 79/200\n",
      "148/148 [==============================] - 10s 64ms/step - loss: 0.0238 - accuracy: 0.1631 - val_loss: 0.0025 - val_accuracy: 0.1676\n",
      "Epoch 80/200\n",
      "148/148 [==============================] - 10s 64ms/step - loss: 0.0241 - accuracy: 0.1627 - val_loss: 0.0030 - val_accuracy: 0.1690\n",
      "Epoch 81/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0245 - accuracy: 0.1627 - val_loss: 0.0022 - val_accuracy: 0.1678\n",
      "Epoch 82/200\n",
      "148/148 [==============================] - 10s 64ms/step - loss: 0.0237 - accuracy: 0.1634 - val_loss: 0.0022 - val_accuracy: 0.1712\n",
      "Epoch 83/200\n",
      "148/148 [==============================] - 10s 64ms/step - loss: 0.0228 - accuracy: 0.1635 - val_loss: 0.0023 - val_accuracy: 0.1676\n",
      "Epoch 84/200\n",
      "148/148 [==============================] - 10s 64ms/step - loss: 0.0228 - accuracy: 0.1632 - val_loss: 0.0032 - val_accuracy: 0.1687\n",
      "Epoch 85/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0222 - accuracy: 0.1635 - val_loss: 0.0023 - val_accuracy: 0.1677\n",
      "Epoch 86/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0215 - accuracy: 0.1635 - val_loss: 0.0020 - val_accuracy: 0.1666\n",
      "Epoch 87/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0213 - accuracy: 0.1639 - val_loss: 0.0020 - val_accuracy: 0.1679\n",
      "Epoch 88/200\n",
      "148/148 [==============================] - 10s 66ms/step - loss: 0.0205 - accuracy: 0.1639 - val_loss: 0.0026 - val_accuracy: 0.1664\n",
      "Epoch 89/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0208 - accuracy: 0.1637 - val_loss: 0.0023 - val_accuracy: 0.1684\n",
      "Epoch 90/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0213 - accuracy: 0.1640 - val_loss: 0.0014 - val_accuracy: 0.1700\n",
      "Epoch 91/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0207 - accuracy: 0.1642 - val_loss: 0.0026 - val_accuracy: 0.1683\n",
      "Epoch 92/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0195 - accuracy: 0.1643 - val_loss: 0.0023 - val_accuracy: 0.1672\n",
      "Epoch 93/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0197 - accuracy: 0.1642 - val_loss: 0.0018 - val_accuracy: 0.1681\n",
      "Epoch 94/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0192 - accuracy: 0.1642 - val_loss: 0.0028 - val_accuracy: 0.1695\n",
      "Epoch 95/200\n",
      "148/148 [==============================] - 10s 64ms/step - loss: 0.0190 - accuracy: 0.1646 - val_loss: 0.0020 - val_accuracy: 0.1684\n",
      "Epoch 96/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0179 - accuracy: 0.1642 - val_loss: 0.0020 - val_accuracy: 0.1670\n",
      "Epoch 97/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0183 - accuracy: 0.1651 - val_loss: 0.0020 - val_accuracy: 0.1686\n",
      "Epoch 98/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0178 - accuracy: 0.1644 - val_loss: 0.0018 - val_accuracy: 0.1699\n",
      "Epoch 99/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0177 - accuracy: 0.1652 - val_loss: 0.0020 - val_accuracy: 0.1707\n",
      "Epoch 100/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0176 - accuracy: 0.1649 - val_loss: 0.0022 - val_accuracy: 0.1674\n",
      "Epoch 101/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0169 - accuracy: 0.1650 - val_loss: 0.0020 - val_accuracy: 0.1689\n",
      "Epoch 102/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0171 - accuracy: 0.1652 - val_loss: 0.0013 - val_accuracy: 0.1681\n",
      "Epoch 103/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0174 - accuracy: 0.1646 - val_loss: 0.0017 - val_accuracy: 0.1695\n",
      "Epoch 104/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0161 - accuracy: 0.1653 - val_loss: 0.0017 - val_accuracy: 0.1688\n",
      "Epoch 105/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0165 - accuracy: 0.1654 - val_loss: 0.0013 - val_accuracy: 0.1693\n",
      "Epoch 106/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0161 - accuracy: 0.1659 - val_loss: 0.0014 - val_accuracy: 0.1695\n",
      "Epoch 107/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0162 - accuracy: 0.1650 - val_loss: 0.0025 - val_accuracy: 0.1696\n",
      "Epoch 108/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0158 - accuracy: 0.1657 - val_loss: 0.0011 - val_accuracy: 0.1687\n",
      "Epoch 109/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0161 - accuracy: 0.1660 - val_loss: 0.0016 - val_accuracy: 0.1682\n",
      "Epoch 110/200\n",
      "148/148 [==============================] - 10s 64ms/step - loss: 0.0161 - accuracy: 0.1657 - val_loss: 0.0012 - val_accuracy: 0.1689\n",
      "Epoch 111/200\n",
      "148/148 [==============================] - 10s 64ms/step - loss: 0.0150 - accuracy: 0.1657 - val_loss: 0.0020 - val_accuracy: 0.1692\n",
      "Epoch 112/200\n",
      "148/148 [==============================] - 10s 64ms/step - loss: 0.0152 - accuracy: 0.1654 - val_loss: 0.0017 - val_accuracy: 0.1702\n",
      "Epoch 113/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/148 [==============================] - 10s 64ms/step - loss: 0.0149 - accuracy: 0.1654 - val_loss: 0.0016 - val_accuracy: 0.1695\n",
      "Epoch 114/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0144 - accuracy: 0.1663 - val_loss: 0.0017 - val_accuracy: 0.1694\n",
      "Epoch 115/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0144 - accuracy: 0.1660 - val_loss: 0.0014 - val_accuracy: 0.1707\n",
      "Epoch 116/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0142 - accuracy: 0.1659 - val_loss: 0.0019 - val_accuracy: 0.1687\n",
      "Epoch 117/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0144 - accuracy: 0.1658 - val_loss: 0.0013 - val_accuracy: 0.1698\n",
      "Epoch 118/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0139 - accuracy: 0.1665 - val_loss: 0.0016 - val_accuracy: 0.1684\n",
      "Epoch 119/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0141 - accuracy: 0.1652 - val_loss: 0.0016 - val_accuracy: 0.1716\n",
      "Epoch 120/200\n",
      "148/148 [==============================] - 10s 64ms/step - loss: 0.0142 - accuracy: 0.1653 - val_loss: 0.0016 - val_accuracy: 0.1715\n",
      "Epoch 121/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0142 - accuracy: 0.1666 - val_loss: 0.0020 - val_accuracy: 0.1674\n",
      "Epoch 122/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0133 - accuracy: 0.1666 - val_loss: 0.0013 - val_accuracy: 0.1692\n",
      "Epoch 123/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0137 - accuracy: 0.1660 - val_loss: 0.0015 - val_accuracy: 0.1689\n",
      "Epoch 124/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0132 - accuracy: 0.1665 - val_loss: 0.0012 - val_accuracy: 0.1711\n",
      "Epoch 125/200\n",
      "148/148 [==============================] - 10s 64ms/step - loss: 0.0133 - accuracy: 0.1663 - val_loss: 0.0014 - val_accuracy: 0.1700\n",
      "Epoch 126/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0127 - accuracy: 0.1660 - val_loss: 0.0019 - val_accuracy: 0.1694\n",
      "Epoch 127/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0123 - accuracy: 0.1666 - val_loss: 0.0014 - val_accuracy: 0.1687\n",
      "Epoch 128/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0128 - accuracy: 0.1658 - val_loss: 0.0015 - val_accuracy: 0.1701\n",
      "Epoch 129/200\n",
      "148/148 [==============================] - 10s 64ms/step - loss: 0.0128 - accuracy: 0.1668 - val_loss: 0.0012 - val_accuracy: 0.1678\n",
      "Epoch 130/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0127 - accuracy: 0.1664 - val_loss: 0.0015 - val_accuracy: 0.1690\n",
      "Epoch 131/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0129 - accuracy: 0.1665 - val_loss: 0.0016 - val_accuracy: 0.1693\n",
      "Epoch 132/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0123 - accuracy: 0.1665 - val_loss: 0.0015 - val_accuracy: 0.1698\n",
      "Epoch 133/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0119 - accuracy: 0.1668 - val_loss: 0.0013 - val_accuracy: 0.1673\n",
      "Epoch 134/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0121 - accuracy: 0.1661 - val_loss: 0.0014 - val_accuracy: 0.1703\n",
      "Epoch 135/200\n",
      "148/148 [==============================] - 10s 64ms/step - loss: 0.0119 - accuracy: 0.1668 - val_loss: 8.8676e-04 - val_accuracy: 0.1687\n",
      "Epoch 136/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0121 - accuracy: 0.1670 - val_loss: 0.0014 - val_accuracy: 0.1687\n",
      "Epoch 137/200\n",
      "148/148 [==============================] - 10s 64ms/step - loss: 0.0116 - accuracy: 0.1669 - val_loss: 0.0016 - val_accuracy: 0.1689\n",
      "Epoch 138/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0114 - accuracy: 0.1668 - val_loss: 0.0016 - val_accuracy: 0.1699\n",
      "Epoch 139/200\n",
      "148/148 [==============================] - 10s 64ms/step - loss: 0.0114 - accuracy: 0.1670 - val_loss: 0.0018 - val_accuracy: 0.1681\n",
      "Epoch 140/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0112 - accuracy: 0.1667 - val_loss: 0.0011 - val_accuracy: 0.1701\n",
      "Epoch 141/200\n",
      "148/148 [==============================] - 10s 64ms/step - loss: 0.0108 - accuracy: 0.1673 - val_loss: 0.0017 - val_accuracy: 0.1708\n",
      "Epoch 142/200\n",
      "148/148 [==============================] - 10s 64ms/step - loss: 0.0111 - accuracy: 0.1672 - val_loss: 0.0013 - val_accuracy: 0.1733\n",
      "Epoch 143/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0111 - accuracy: 0.1669 - val_loss: 0.0015 - val_accuracy: 0.1686\n",
      "Epoch 144/200\n",
      "148/148 [==============================] - 10s 64ms/step - loss: 0.0105 - accuracy: 0.1675 - val_loss: 0.0011 - val_accuracy: 0.1694\n",
      "Epoch 145/200\n",
      "148/148 [==============================] - 10s 64ms/step - loss: 0.0112 - accuracy: 0.1671 - val_loss: 0.0015 - val_accuracy: 0.1704\n",
      "Epoch 146/200\n",
      "148/148 [==============================] - 10s 64ms/step - loss: 0.0103 - accuracy: 0.1674 - val_loss: 0.0012 - val_accuracy: 0.1700\n",
      "Epoch 147/200\n",
      "148/148 [==============================] - 10s 64ms/step - loss: 0.0110 - accuracy: 0.1672 - val_loss: 0.0012 - val_accuracy: 0.1704\n",
      "Epoch 148/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0107 - accuracy: 0.1668 - val_loss: 0.0015 - val_accuracy: 0.1699\n",
      "Epoch 149/200\n",
      "148/148 [==============================] - 10s 64ms/step - loss: 0.0099 - accuracy: 0.1671 - val_loss: 0.0025 - val_accuracy: 0.1693\n",
      "Epoch 150/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0103 - accuracy: 0.1679 - val_loss: 0.0011 - val_accuracy: 0.1685\n",
      "Epoch 151/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0101 - accuracy: 0.1672 - val_loss: 0.0012 - val_accuracy: 0.1695\n",
      "Epoch 152/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0104 - accuracy: 0.1668 - val_loss: 0.0015 - val_accuracy: 0.1686\n",
      "Epoch 153/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0103 - accuracy: 0.1662 - val_loss: 0.0011 - val_accuracy: 0.1717\n",
      "Epoch 154/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0099 - accuracy: 0.1671 - val_loss: 0.0015 - val_accuracy: 0.1690\n",
      "Epoch 155/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0102 - accuracy: 0.1677 - val_loss: 0.0011 - val_accuracy: 0.1699\n",
      "Epoch 156/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0095 - accuracy: 0.1671 - val_loss: 0.0018 - val_accuracy: 0.1705\n",
      "Epoch 157/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0098 - accuracy: 0.1672 - val_loss: 0.0014 - val_accuracy: 0.1698\n",
      "Epoch 158/200\n",
      "148/148 [==============================] - 10s 64ms/step - loss: 0.0099 - accuracy: 0.1675 - val_loss: 8.6014e-04 - val_accuracy: 0.1700\n",
      "Epoch 159/200\n",
      "148/148 [==============================] - 10s 64ms/step - loss: 0.0098 - accuracy: 0.1672 - val_loss: 0.0014 - val_accuracy: 0.1692\n",
      "Epoch 160/200\n",
      "148/148 [==============================] - 10s 64ms/step - loss: 0.0096 - accuracy: 0.1672 - val_loss: 0.0015 - val_accuracy: 0.1686\n",
      "Epoch 161/200\n",
      "148/148 [==============================] - 10s 64ms/step - loss: 0.0099 - accuracy: 0.1677 - val_loss: 0.0013 - val_accuracy: 0.1683\n",
      "Epoch 162/200\n",
      "148/148 [==============================] - 10s 64ms/step - loss: 0.0100 - accuracy: 0.1675 - val_loss: 7.1585e-04 - val_accuracy: 0.1683\n",
      "Epoch 163/200\n",
      "148/148 [==============================] - 10s 64ms/step - loss: 0.0096 - accuracy: 0.1671 - val_loss: 6.8976e-04 - val_accuracy: 0.1697\n",
      "Epoch 164/200\n",
      "148/148 [==============================] - 10s 64ms/step - loss: 0.0092 - accuracy: 0.1671 - val_loss: 0.0016 - val_accuracy: 0.1703\n",
      "Epoch 165/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0100 - accuracy: 0.1675 - val_loss: 0.0012 - val_accuracy: 0.1701\n",
      "Epoch 166/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0091 - accuracy: 0.1680 - val_loss: 0.0011 - val_accuracy: 0.1681\n",
      "Epoch 167/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0090 - accuracy: 0.1678 - val_loss: 0.0012 - val_accuracy: 0.1715\n",
      "Epoch 168/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0087 - accuracy: 0.1687 - val_loss: 0.0015 - val_accuracy: 0.1683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0093 - accuracy: 0.1671 - val_loss: 0.0013 - val_accuracy: 0.1696\n",
      "Epoch 170/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0094 - accuracy: 0.1683 - val_loss: 0.0015 - val_accuracy: 0.1687\n",
      "Epoch 171/200\n",
      "148/148 [==============================] - 9s 64ms/step - loss: 0.0090 - accuracy: 0.1678 - val_loss: 0.0012 - val_accuracy: 0.1687\n",
      "Epoch 172/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0089 - accuracy: 0.1672 - val_loss: 0.0018 - val_accuracy: 0.1669\n",
      "Epoch 173/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0091 - accuracy: 0.1674 - val_loss: 0.0012 - val_accuracy: 0.1695\n",
      "Epoch 174/200\n",
      "148/148 [==============================] - 10s 64ms/step - loss: 0.0085 - accuracy: 0.1679 - val_loss: 0.0010 - val_accuracy: 0.1693\n",
      "Epoch 175/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0083 - accuracy: 0.1678 - val_loss: 0.0015 - val_accuracy: 0.1697\n",
      "Epoch 176/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0082 - accuracy: 0.1678 - val_loss: 0.0014 - val_accuracy: 0.1691\n",
      "Epoch 177/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0084 - accuracy: 0.1682 - val_loss: 7.8510e-04 - val_accuracy: 0.1695\n",
      "Epoch 178/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0085 - accuracy: 0.1675 - val_loss: 8.8083e-04 - val_accuracy: 0.1702\n",
      "Epoch 179/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0089 - accuracy: 0.1674 - val_loss: 0.0012 - val_accuracy: 0.1672\n",
      "Epoch 180/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0084 - accuracy: 0.1682 - val_loss: 0.0011 - val_accuracy: 0.1682\n",
      "Epoch 181/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0086 - accuracy: 0.1671 - val_loss: 0.0012 - val_accuracy: 0.1709\n",
      "Epoch 182/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0086 - accuracy: 0.1678 - val_loss: 0.0013 - val_accuracy: 0.1713\n",
      "Epoch 183/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0082 - accuracy: 0.1679 - val_loss: 0.0012 - val_accuracy: 0.1686\n",
      "Epoch 184/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0080 - accuracy: 0.1680 - val_loss: 0.0015 - val_accuracy: 0.1696\n",
      "Epoch 185/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0081 - accuracy: 0.1682 - val_loss: 0.0015 - val_accuracy: 0.1703\n",
      "Epoch 186/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0082 - accuracy: 0.1679 - val_loss: 0.0012 - val_accuracy: 0.1692\n",
      "Epoch 187/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0076 - accuracy: 0.1690 - val_loss: 0.0016 - val_accuracy: 0.1672\n",
      "Epoch 188/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0080 - accuracy: 0.1684 - val_loss: 0.0011 - val_accuracy: 0.1678\n",
      "Epoch 189/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0076 - accuracy: 0.1683 - val_loss: 0.0014 - val_accuracy: 0.1692\n",
      "Epoch 190/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0081 - accuracy: 0.1673 - val_loss: 0.0014 - val_accuracy: 0.1699\n",
      "Epoch 191/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0081 - accuracy: 0.1685 - val_loss: 9.7685e-04 - val_accuracy: 0.1705\n",
      "Epoch 192/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0075 - accuracy: 0.1686 - val_loss: 0.0011 - val_accuracy: 0.1684\n",
      "Epoch 193/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0085 - accuracy: 0.1684 - val_loss: 0.0014 - val_accuracy: 0.1698\n",
      "Epoch 194/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0078 - accuracy: 0.1682 - val_loss: 0.0012 - val_accuracy: 0.1683\n",
      "Epoch 195/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0078 - accuracy: 0.1690 - val_loss: 9.9107e-04 - val_accuracy: 0.1708\n",
      "Epoch 196/200\n",
      "148/148 [==============================] - 10s 64ms/step - loss: 0.0079 - accuracy: 0.1680 - val_loss: 0.0012 - val_accuracy: 0.1708\n",
      "Epoch 197/200\n",
      "148/148 [==============================] - 10s 64ms/step - loss: 0.0073 - accuracy: 0.1684 - val_loss: 0.0012 - val_accuracy: 0.1710\n",
      "Epoch 198/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0081 - accuracy: 0.1685 - val_loss: 0.0010 - val_accuracy: 0.1704\n",
      "Epoch 199/200\n",
      "148/148 [==============================] - 10s 64ms/step - loss: 0.0071 - accuracy: 0.1686 - val_loss: 9.1999e-04 - val_accuracy: 0.1710\n",
      "Epoch 200/200\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.0075 - accuracy: 0.1693 - val_loss: 0.0015 - val_accuracy: 0.1694\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 200\n",
    "tf.random.set_seed(SEED)\n",
    "history=model.fit(train_dataset,validation_data=val_dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "W0rn452ewfRC"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# history에서 metric 추출\n",
    "acc = history.history.get('accuracy')\n",
    "val_acc = history.history.get('val_accuracy')\n",
    "loss = history.history.get('loss')\n",
    "val_loss = history.history.get('val_loss')\n",
    "\n",
    "# plot\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Accuracy Plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(acc, label='Train Acc')\n",
    "plt.plot(val_acc, label='Val Acc')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Loss Plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(loss, label='Train Loss')\n",
    "plt.plot(val_loss, label='Val Loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zf6BE7vJwf1D"
   },
   "source": [
    "#5.inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y-UayrujwlF-",
    "outputId": "ce0682cd-e011-4e65-beb3-66e0a1f6073a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def decoder_inference(sentence):\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
    "  # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
    "\n",
    "  sentence = tf.expand_dims(tokenizer.encode(sentence),axis=0)\n",
    "  if len(sentence) <= MAX_LENGTH:\n",
    "    sentence = tf.concat([sentence, tf.zeros((1, MAX_LENGTH - len(sentence)),dtype=sentence.dtype)], axis=-1)\n",
    "  # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
    "  # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
    "  output_sequence = sentence\n",
    "\n",
    "  # 디코더의 인퍼런스 단계\n",
    "  for i in range(MAX_LENGTH):\n",
    "    # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
    "    predictions = model(inputs=[output_sequence], training=False)\n",
    "    predictions = predictions[:, -1:, :]\n",
    "\n",
    "    # 현재 예측한 단어의 정수\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "    # 만약 현재 예측한 단어가 pad 토큰이라면 for문을 종료\n",
    "    if tf.equal(predicted_id, 0):\n",
    "      break\n",
    "\n",
    "    # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
    "    # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
    "    output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "  return tf.squeeze(output_sequence, axis=0)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LdfyXzf6wp70",
    "outputId": "ce068586-58fe-48f2-8d2d-5813a2999ffa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def sentence_generation(sentence):\n",
    "  # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
    "  prediction = decoder_inference(sentence)\n",
    "\n",
    "  prediction = prediction[18:]\n",
    "\n",
    "  # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
    "  predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size and i !=0])\n",
    "\n",
    "  print('입력 : {}'.format(sentence))\n",
    "  print('출력 : {}'.format(predicted_sentence))\n",
    "\n",
    "  return predicted_sentence\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tCrn5-BbyrOW",
    "outputId": "a9fc9968-cf19-4c2f-dc73-96f419c63fe3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "흰머리 보여\n",
      "기다림 속에 갇혀 있어\n",
      "나를 너무 오래 기다리게했어\n",
      "강아지 좋아하는 여자 어때 ?\n",
      "중고로 사길 잘 한거 같아\n",
      "대학 가고 싶다.\n",
      "어른이 된다는 건 뭘까\n",
      "먼지가 너무 많아\n",
      "사랑이라는 이름으로\n",
      "잘 살겠지 라고 생각하자\n",
      "어디서 피해자 코스프레임 ?\n",
      "속았나\n",
      "양키캔들 선물받았어\n",
      "남자후폭풍\n",
      "이별후 재회 그리고\n",
      "늦어지고 있는데 변명이 생각 안나\n",
      "이력서 쓰고 있어.\n",
      "머리 또 잘라야 돼\n",
      "연락하고 지내는데\n",
      "나 쉬운 여자 아니야\n",
      "싸구려 인생\n",
      "사랑 받는 느낌을 못 받아\n",
      "지치네\n",
      "문자 보내놓은지 어언 한 달.\n",
      "같은 반인데 헤어지자고 해야 하나 ? ?\n",
      "서울 근교에서 갈만한 곳 추천\n",
      "남자친구가 이벤트 해 주면 좋겠다.\n",
      "향수 뭐로 할까\n",
      "잘 지냈어 ?\n",
      "답정녀 좀 싫어\n",
      "코딩 좀 배울까\n",
      "잠들기 직전 일어난 직후는 죽을 것 같네\n",
      "인형뽑기는 유행 지났지 ?\n",
      "좀 쉬면서 애기 키워야 할 듯\n",
      "오랜만에 스테끼 먹고 싶어\n",
      "썸 타는 중인데 난 직장인이고 얘는 학생이야.\n",
      "아직도 꿈같고 너무 괴로워\n",
      "내가 쓸모없는 인간 같아\n",
      "어째야 할까\n",
      "만나면 좋은 사람이 있어. 헤헤\n",
      "이별후 3일째\n",
      "부모님이 이혼할 거 같아\n",
      "넌 잘살더라\n",
      "썸남이 같이 운동하자는데 가능 ?\n",
      "한달 ! ! 하고 일주일\n",
      "절망적인데\n",
      "말을 왜 이렇게 못 알아 듣니\n",
      "전화 못하겠어\n",
      "그 남자를 좋아해도 되는지 고민이야.\n",
      "남친이 나를 안 좋아하는 것 같은데 내가 붙잡고 있는 것 같아.\n",
      "남사친이랑 잘 맞아서 카톡이 끊어지지 않는데 이거 그린라이트일까 ?\n",
      "탄생의 이유 알아 ?\n",
      "너 뭐하는 애야\n",
      "어제 연락이 왔어. 제가 매달려서 온거같아\n",
      "그녀를 만났던 카페에서 탈퇴했어\n",
      "겨울에 하는 이별\n",
      "신기한 일들이 많이 일어나\n",
      "회식하는데 나만 챙겨줘. 썸임 ?\n",
      "여자친구가 자주 씻지를 않아.\n",
      "이 사람이랑 결혼이 옳은 걸까 ?\n",
      "업무 지적을 너무 많이 받아\n",
      "너무 마른 거 같아\n",
      "나 좀 쩌는 듯\n",
      "내가 좋아하는 사람이 나 안 좋아하는 거 같아\n"
     ]
    }
   ],
   "source": [
    "for x, y in val_dataset.take(1):\n",
    "    dec_inputs = x['dec_inputs']    # dict에서 꺼내\n",
    "    tokens = dec_inputs[:, :17]      # slicing\n",
    "    for token_seq in tokens:         # batch 안에서 하나씩\n",
    "        print(tokenizer.decode([t for t in token_seq.numpy() if t != 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 내가 좋아하는 사람이 나 안 좋아하는 거 같아\n",
      "출력 : 슬픈 이야기네요...............\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'슬픈 이야기네요...............'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('내가 좋아하는 사람이 나 안 좋아하는 거 같아')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KeTRA_udwh8l"
   },
   "source": [
    "#6.masked_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "sBQw3H7E1ECq"
   },
   "outputs": [],
   "source": [
    "def create_diag_mask(x):\n",
    "  batch=tf.shape(x)[0]\n",
    "  seq_len = tf.shape(x)[1]\n",
    "  diag = tf.eye(num_rows=seq_len, num_columns=seq_len)  # (S, S)\n",
    "  diag = tf.repeat(diag[tf.newaxis,:,:], repeats=batch , axis=0)\n",
    "  return diag[:, :, :, tf.newaxis] # (B, S, S, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5NYEa2flzwCM",
    "outputId": "813e9ad7-bf90-425e-be12-5aace3822588"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "class MultiHeadAttention2(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, kernel_initializer='glorot_uniform',name=\"multi_head_attention\"):\n",
    "    super(MultiHeadAttention2, self).__init__(name=name)\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "    self.kernel_initializer = tf.keras.initializers.get(kernel_initializer)\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    self.query_dense = tf.keras.layers.Dense(units=d_model,kernel_initializer=self.kernel_initializer)\n",
    "    self.key_dense = tf.keras.layers.Dense(units=d_model,kernel_initializer=self.kernel_initializer)\n",
    "    self.value_dense = tf.keras.layers.Dense(units=d_model,kernel_initializer=self.kernel_initializer)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(units=d_model,kernel_initializer=self.kernel_initializer)\n",
    "\n",
    "  def split_heads(self, inputs, batch_size, seq_len):\n",
    "    inputs = tf.reshape(\n",
    "        inputs, shape=(batch_size, -1, seq_len, self.num_heads, self.depth))\n",
    "    return tf.transpose(inputs, perm=[0, 3, 1, 2, 4])\n",
    "\n",
    "  def call(self, inputs):\n",
    "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "        'value'], inputs['mask']\n",
    "    batch_size = tf.shape(query)[0]\n",
    "    seq_len=tf.shape(query)[1]\n",
    "\n",
    "    # Q, K, V에 각각 Dense를 적용합니다\n",
    "    query = self.query_dense(query)\n",
    "    key = self.key_dense(key)\n",
    "    value = self.value_dense(value)\n",
    "\n",
    "    # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
    "    query = self.split_heads(query,batch_size,tf.shape(query)[2])\n",
    "    key = self.split_heads(key,batch_size,tf.shape(key)[2])\n",
    "    value = self.split_heads(value,batch_size,tf.shape(value)[2])\n",
    "\n",
    "    # 스케일드 닷 프로덕트 어텐션 함수\n",
    "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 3, 1, 4])\n",
    "\n",
    "    # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
    "    concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, seq_len, -1, self.d_model))\n",
    "\n",
    "    # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
    "    outputs = self.dense(concat_attention)\n",
    "\n",
    "    return outputs\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pOAeY2sA0Epn",
    "outputId": "a5d392f8-a466-4dae-f961-d062a9473400"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 디코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "  inputs2 = tf.keras.Input(shape=(None, None, d_model), name=\"inputs2\")\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None, None), name=\"look_ahead_mask\")\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention1 = MultiHeadAttention2(\n",
    "      d_model, num_heads, kernel_initializer=initializer, name=\"attention_1\")(inputs={\n",
    "          'query': inputs2,\n",
    "          'key': inputs2,\n",
    "          'value': inputs2,\n",
    "          'mask': look_ahead_mask\n",
    "      })\n",
    "\n",
    "  # 마스크드 멀티 헤드 어텐션의 결과는\n",
    "  # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention1 = tf.keras.layers.Dropout(rate=dropout)(attention1)\n",
    "  attention1 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "  # 세 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu',kernel_initializer=initializer)(attention1)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model,kernel_initializer=initializer)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(outputs + attention1)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs2,look_ahead_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V7fyreF10Ltp",
    "outputId": "7ec835e2-e307-426d-de30-7cdf2c3f6881"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            max_len,\n",
    "            name='decoder'):\n",
    "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None, None), name='look_ahead_mask')\n",
    "\n",
    "  # 임베딩 레이어\n",
    "  embedding_layer = tf.keras.layers.Embedding(vocab_size, d_model,embeddings_initializer=initializer)\n",
    "  embeddings = embedding_layer(inputs)\n",
    "  #embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  positions = tf.keras.Input(shape=(None,), name='positions')\n",
    "  position_embeddings = tf.keras.layers.Embedding(max_len, d_model,embeddings_initializer=initializer)(positions)\n",
    "\n",
    "  embeddings += position_embeddings\n",
    "\n",
    "  # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  outputs2 = tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=1),output_shape=(1,None,d_model))(outputs)\n",
    "  outputs2 = tf.keras.layers.Lambda(lambda x: tf.repeat(x, repeats=tf.shape(x)[2], axis=1),output_shape=(None,None,d_model))(outputs2)\n",
    "  diag_mask = tf.keras.layers.Lambda(create_diag_mask)(outputs2)\n",
    "  for i in range(num_layers):\n",
    "    if i >= 1:\n",
    "      outputs = tf.keras.layers.Lambda(lambda x : tf.multiply(x[0], x[1]),output_shape=(None,None,d_model))([diag_mask,outputs])\n",
    "    outputs2 = decoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name='decoder_layer_{}'.format(i),\n",
    "    )(inputs=[outputs2, look_ahead_mask])\n",
    "\n",
    "  final_outputs = tf.keras.layers.Lambda(lambda x: tf.transpose(tf.linalg.diag_part(tf.transpose(x, perm=[0,3,1,2])),perm=[0,2,1]),output_shape=(None, d_model))(outputs2)\n",
    "  embedding_weights = embedding_layer.weights[0]\n",
    "  outputs2 = tf.keras.layers.Lambda(lambda x: tf.matmul(x[0],x[1],transpose_b=True),output_shape=(None,vocab_size))([final_outputs,embedding_weights])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, positions, look_ahead_mask],\n",
    "      outputs=outputs2,\n",
    "      name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xoEo1lEI0OOn",
    "outputId": "b4d7d5ce-7fdc-44ff-acc5-11b7de9b7fe0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                max_len,\n",
    "                name=\"transformer\"):\n",
    "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "  # 인코더에서 패딩을 위한 마스크\n",
    "  enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(inputs)\n",
    "\n",
    "  # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
    "  # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "  look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_real_mask,\n",
    "      output_shape=(1, None, None, None),\n",
    "      name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "  # 디코더\n",
    "  dec_outputs = decoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "      max_len=max_len\n",
    "  )(inputs=[dec_inputs, look_ahead_mask])\n",
    "\n",
    "  # 완전연결층\n",
    "  # final_outputs = tf.keras.layers.Lambda(lambda x: tf.transpose(tf.linalg.diag_part(tf.transpose(x, perm=[0,3,1,2])),perm=[0,2,1]),output_shape=(None, d_model))(dec_outputs)\n",
    "  # outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(final_outputs)\n",
    "\n",
    "  return tf.keras.Model(inputs=dec_inputs, outputs=outputs, name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "id": "6SRPH0LA2Def",
    "outputId": "25d4650d-cb68-4519-fed0-c5935b8b7235"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"transformer\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ dec_inputs          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positions (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dec_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ look_ahead_mask     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dec_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │ <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,739,392</span> │ dec_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">10456</span>)            │            │ positions[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ look_ahead_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ dec_inputs          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positions (\u001b[38;5;33mLambda\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ dec_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ look_ahead_mask     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;45mNone\u001b[0m,   │          \u001b[38;5;34m0\u001b[0m │ dec_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mLambda\u001b[0m)            │ \u001b[38;5;45mNone\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │  \u001b[38;5;34m3,739,392\u001b[0m │ dec_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │ \u001b[38;5;34m10456\u001b[0m)            │            │ positions[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ look_ahead_mask[\u001b[38;5;34m…\u001b[0m │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,739,392</span> (14.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,739,392\u001b[0m (14.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,739,392</span> (14.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,739,392\u001b[0m (14.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수\n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.2 # 드롭아웃의 비율\n",
    "\n",
    "model2 = transformeraa(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT,\n",
    "    max_len=MAX_LENGTH*2-1)\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RyiH2tPA2Nha",
    "outputId": "821619e6-cb47-46ed-aa36-340736b27bb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH*2 - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model2.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "id": "2EuwUzqE8K19",
    "outputId": "b8aa98bc-6453-4974-c653-fedcd3d58aca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: dec_inputs\n",
      "Received: inputs=['Tensor(shape=(None, 33))']\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Expected float32, but got outputs of type 'str'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-130-2e68553519ba>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSEED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optree/ops.py\u001b[0m in \u001b[0;36mtree_map\u001b[0;34m(func, tree, is_leaf, none_is_leaf, namespace, *rests)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0mleaves\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtreespec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_leaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnone_is_leaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0mflat_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mleaves\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtreespec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_up_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrests\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtreespec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mflat_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected float32, but got outputs of type 'str'."
     ]
    }
   ],
   "source": [
    "EPOCHS = 200\n",
    "tf.random.set_seed(SEED)\n",
    "history=model2.fit(train_dataset,validation_data=val_dataset, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# history에서 metric 추출\n",
    "acc = history.history.get('accuracy')\n",
    "val_acc = history.history.get('val_accuracy')\n",
    "loss = history.history.get('loss')\n",
    "val_loss = history.history.get('val_loss')\n",
    "\n",
    "# plot\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Accuracy Plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(acc, label='Train Acc')\n",
    "plt.plot(val_acc, label='Val Acc')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Loss Plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(loss, label='Train Loss')\n",
    "plt.plot(val_loss, label='Val Loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
