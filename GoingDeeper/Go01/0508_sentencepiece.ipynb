{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install konlpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aqe0ZIsbNy5",
        "outputId": "4d97b93f-2a5f-48c1-ba68-87e2e461da1f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting JPype1>=0.7.0 (from konlpy)\n",
            "  Downloading jpype1-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.11/dist-packages (from konlpy) (5.4.0)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.11/dist-packages (from konlpy) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from JPype1>=0.7.0->konlpy) (24.2)\n",
            "Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m112.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jpype1-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (494 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.1/494.1 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.5.2 konlpy-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "mecab, kkoran, sentencepiece bpe, sentencepiece unigram"
      ],
      "metadata": {
        "id": "qopsebJyeZdw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install emoji"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtT8lK926eYe",
        "outputId": "16ee3b59-1a04-4dfd-d97b-b88776838f87"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting emoji\n",
            "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Downloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/590.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m583.7/590.6 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: emoji\n",
            "Successfully installed emoji-2.14.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_GLzrUkZiU6",
        "outputId": "de6f4c87-ce26-498d-cbda-5899ee92719b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.18.0\n",
            "2.0.2\n",
            "0.6.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import konlpy\n",
        "\n",
        "print(tf.__version__)\n",
        "print(np.__version__)\n",
        "print(konlpy.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "\n",
        "set_seed(42)"
      ],
      "metadata": {
        "id": "pfxRffyBgYA1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "SzzP5KsXgkPV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('ratings_train.txt', sep='\\t')\n",
        "test = pd.read_csv('ratings_test.txt', sep='\\t')"
      ],
      "metadata": {
        "id": "ViCLX6EDgjJc"
      },
      "execution_count": 573,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stopword= pd.read_csv('stopwords-ko.txt', names=['stopword'], header=None)"
      ],
      "metadata": {
        "id": "M866yDzorEo9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_word=stopword['stopword'].to_list()"
      ],
      "metadata": {
        "id": "-31NzWCPrQ3a"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. http 링크 제거\n",
        "2. 영어? A급 B급 C급 -> 우수, 평타, 최악  / 동의어 다의어 표현 피함\n",
        "3. -_-, -.- -> 지루 , ^-^ -> 행복 으로 교체\n",
        "4. 1점 2점.. -> 일점, 이점 .. 십점 / 1개 2개... -> 한개 두개 세개 네개 ..열개 / 1위 2위... -> 일위 이위 삼위 ... /  이외 숫자 제거\n",
        "4. 이모지 - 하트 ♥ -> 최고\n",
        "5. .., ..., .... -> ...  / ~ ! ? 이 3개 특수기호 중복을 하나로 줄이고 나머지 특수기호 다 제거\n",
        "6. O alphabet 대문자 O 가 연속적으로 표현 되는 것 강한 욕설 씨발 로 교체\n",
        "7. ㅋㅋ,ㅎㅎ,ㅠㅠ,ㅜㅜ 유지 ㅋㅋㅋ ㅎㅎㅎ ㅠㅠㅠ ㅜㅜㅜ 이런거는 다 2개 짜리로 바꿈\n",
        "8.\n",
        "9. 영어 제거\n",
        "10. 공백 중복된거 공백 하나로 교체\n",
        "11. 빈 텍스트 np.nan 교체\n",
        "12. ㄱㅅ, ㄳ -> 감사\n",
        "13. 반복된 자모문자\n",
        "15. ㅗ\n",
        "16. good, great, awesome ->\n",
        "17. bad, shit\n",
        "18. 1류, 2류, 3류, 4류, 5류 -> 일류, 이류, 삼류, 사류, 오류\n",
        "19. ㄵ ㄴㅈ\n",
        "20. 숫자를 그냥 지워야 되나?\n",
        "21. 한글자 자모 지우"
      ],
      "metadata": {
        "id": "-GWZmoi-j2vz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델은 bi lstm classify head"
      ],
      "metadata": {
        "id": "6kZthc5alMmg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "띄어쓰기 잘못된 것은 짧은 문장 필터링 할때 걸러내기, 맞춤법 검사기 cost"
      ],
      "metadata": {
        "id": "Yk2n82myq2pp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">,< >ㅁ< , >_<"
      ],
      "metadata": {
        "id": "rND31ShagbqR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train['document'][520]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "bxVAhINOyjtp",
        "outputId": "e3b6c7ff-58e2-4127-dfe9-b5e03e21ad62"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'그냥 재미가 없어요....ㅠㅠ'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "custom_preprocess(train['document'][520],stop_word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "16VbgNuOycQc",
        "outputId": "4cc25d49-41c2-4e7c-e8f4-ff074dbaaf90"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'그냥 재미가 없어요...<bb>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import emoji\n",
        "\n",
        "\n",
        "def custom_preprocess(text, stop_words=None):\n",
        "  # 1. 입력값 string 확인\n",
        "  if not isinstance(text, str):\n",
        "      return text\n",
        "\n",
        "  # 2. http 링크 제거\n",
        "  text = re.sub(r\"(https?://[^\\s가-힣]*)|(www\\.[^\\s가-힣]*)\", \" \", text)\n",
        "\n",
        "  text = re.sub(r\"g[o]{2,}d+\", \"good\", text, flags=re.IGNORECASE)\n",
        "\n",
        "  happy_words = [\n",
        "    \"good\", \"great\", \"awesome\", \"amazing\", \"fantastic\", \"excellent\",\n",
        "    \"wonderful\", \"fabulous\", \"nice\", \"perfect\", \"superb\", \"brilliant\",\n",
        "    \"love\", \"loved\", \"lovely\", \"enjoyable\", \"cool\", \"best\", \"favorite\", \"incredible\"\n",
        "  ]\n",
        "\n",
        "  bad_words = [\n",
        "    \"bad\", \"awful\", \"terrible\", \"horrible\", \"worst\", \"shit\",\n",
        "    \"sucks\", \"poor\", \"hate\", \"hated\", \"disgusting\", \"dreadful\",\n",
        "    \"lame\", \"crappy\", \"pathetic\", \"boring\", \"disappointing\",\n",
        "    \"annoying\", \"stupid\", \"waste\"\n",
        "  ]\n",
        "\n",
        "  for word in happy_words:\n",
        "    text = re.sub(rf\"\\b{word}\\b\", \"<good>\", text, flags=re.IGNORECASE)\n",
        "    # 부정 단어 → <bad>\n",
        "  for word in bad_words:\n",
        "    text = re.sub(rf\"\\b{word}\\b\", \"<bad>\", text, flags=re.IGNORECASE)\n",
        "\n",
        "  # 3. A급 B급 C급 → 우수 평타 최악\n",
        "  text = text.replace(\"A급\", \"우수\").replace(\"B급\", \"평타\").replace(\"C급\", \"최악\")\n",
        "\n",
        "  # 4. -_- → 지루, ^-^ → 행복\n",
        "  text = text.replace(\"ㄵ\", \"지루\").replace(\"ㄴㅈ\", \"지루\")\n",
        "\n",
        "  profanity_patterns = [\"ㅅㅂ\", \"ㅈㄹ\", \"ㅇㅈㄹ\", \"ㅄ\", \"ㅂㅅ\"]\n",
        "  for word in profanity_patterns:\n",
        "    # 단어 경계로 감싸서 독립된 단어로만 매칭\n",
        "    text = re.sub(rf\"\\b{word}\\b\", \"<profanity>\", text)\n",
        "\n",
        "  for normal_face in [\"-.-\", \"-,-\", \"-_-\",\"--\",\"- -\",\"=_=\"]:\n",
        "    text = text.replace(normal_face, \"<NormalToken>\")\n",
        "  for sad_face in [\"ㅠ.ㅠ\",\"ㅠㅡㅠ\",\"ㅠ,ㅠ\",\"ㅠ_ㅠ\",\"ㅜ.ㅜ\",\"ㅜㅡㅜ\",\"ㅜ,ㅜ\",\"ㅜ_ㅜ\",\"ㅠ ㅠ\",\"ㅜ ㅜ\",\"ㅠ ㅜ\",\"ㅜ ㅠ\"]:\n",
        "    text = text.replace(sad_face, \"<SadToken>\")\n",
        "  # HappyToken\n",
        "  for happy_face in [\"^-^\", \"^.^\", \"^,^\",\"^_^\",\"^^\",\"^ ^\",\"> <\",\">_<\",\">.<\",\">ㅁ<\"]:\n",
        "    text = text.replace(happy_face, \"<HappyToken>\")\n",
        "\n",
        "  text = re.sub(\"-\",\" \", text)\n",
        "\n",
        "  # 5. 숫자 변환\n",
        "  num_map = {\n",
        "    \"1점\": \"일점\", \"2점\": \"이점\", \"3점\": \"삼점\", \"4점\": \"사점\", \"5점\": \"오점\",\n",
        "    \"6점\": \"육점\", \"7점\": \"칠점\", \"8점\": \"팔점\", \"9점\": \"구점\", \"10점\": \"십점\",\n",
        "    \"1개\": \"한개\", \"2개\": \"두개\", \"3개\": \"세개\", \"4개\": \"네개\", \"5개\": \"다섯개\",\n",
        "    \"6개\": \"여섯개\", \"7개\": \"일곱개\", \"8개\": \"여덟개\", \"9개\": \"아홉개\", \"10개\": \"열개\",\n",
        "    \"1위\": \"일위\", \"2위\": \"이위\", \"3위\": \"삼위\", \"4위\": \"사위\", \"5위\": \"오위\",\n",
        "    \"6위\": \"육위\", \"7위\": \"칠위\", \"8위\": \"팔위\", \"9위\": \"구위\", \"10위\": \"십위\",\n",
        "    \"1류\": \"일류\", \"2류\": \"이류\", \"3류\": \"삼류\", \"4류\": \"사류\", \"5류\": \"오류\", \"1등\": \"일등\"\n",
        "}\n",
        "  for k, v in num_map.items():\n",
        "      text = text.replace(k, v)\n",
        "\n",
        "  # 1. 숫자+빠다+붙는글자 제거\n",
        "  text = re.sub(r\"\\d+빠다[가-힣]*\", \"\", text)\n",
        "\n",
        "  # 2. 2등~5등 제거\n",
        "  text = re.sub(r\"[2-5]등\", \"\", text)\n",
        "\n",
        "  text = re.sub(r\"(ㄱㅅ|ㄳ)\", \"감사 \", text)\n",
        "\n",
        "  # 6. ♥ → 최고\n",
        "  text = text.replace(\"♥\", \"최고 \").replace(\"♡\", \"최고 \")\n",
        "  text = emoji.replace_emoji(text, replace=' ')\n",
        "\n",
        "  # 7. ... 처리\n",
        "  text = re.sub(r\"\\.{2,}\", \"... \", text)\n",
        "\n",
        "  # 1. ... → <TRIPLE_DOT>로 임시 치환\n",
        "  text = re.sub(r\"\\.{3}\", \"<TRIPLE_DOT>\", text)\n",
        "\n",
        "  # 2. 나머지 . 제거\n",
        "  text = re.sub(r\"\\.\", \" \", text)\n",
        "\n",
        "  # 3. <TRIPLE_DOT> → ... 복원\n",
        "  text = text.replace(\"<TRIPLE_DOT>\", \"...\")\n",
        "\n",
        "  # 8. ~!?, 연속 → 한 개로\n",
        "  text = re.sub(r\"[~]{2,}\", \"~\", text)\n",
        "  text = re.sub(r\"[!]{2,}\", \"!\", text)\n",
        "  text = re.sub(r\"[?]{2,}\", \"?\", text)\n",
        "\n",
        "  # 1. !? 또는 ?! 반복 패턴 → <wow>로 보호\n",
        "  text = re.sub(r\"(!\\?|!\\?)+|(\\?!|\\?!)+\", \"<wow>\", text)\n",
        "\n",
        "  # 2. !, ?, ~, <wow> 뒤에 공백 추가\n",
        "  text = re.sub(r\"([!?~]|<wow>)\", r\"\\1 \", text)\n",
        "\n",
        "  # 3. <wow> 복원\n",
        "  text = text.replace(\"<wow>\", \"!?\")\n",
        "\n",
        "  # 9. O 연속 → 씨발\n",
        "  text = re.sub(r\"\\S*O{2,}\\S*\", \"<filter> \", text)\n",
        "\n",
        "  # 10. ㅋㅋ 이상 → ㅋㅋ\n",
        "  text = re.sub(r\"ㅋ{2,}\", \"<zz> \", text)\n",
        "  # ㅎㅎ 이상 → ㅎㅎ\n",
        "  text = re.sub(r\"ㅎ{2,}\", \"<HappyToken> \", text)\n",
        "  # ㅠㅠ 이상 → ㅠㅠ\n",
        "  text = re.sub(r\"ㅠ{2,}\", \"<SadToken> \", text)\n",
        "  # ㅜㅜ 이상 → ㅜㅜ\n",
        "  text = re.sub(r\"ㅜ{2,}\", \"<SadToken> \", text)\n",
        "  text = re.sub(r\"(ㅠㅜ|ㅜㅠ)\", \"<SadToken> \", text)\n",
        "\n",
        "  text = re.sub(r\"ㅗ{2,}\", \"<hh> \", text)\n",
        "\n",
        "  text = re.sub(r\"([가-힣])\\1{2,}\", r\"\\1\\1\", text)\n",
        "\n",
        "  text = re.sub(r\";+\", \";\", text)\n",
        "\n",
        "  # 14. stop_words 제거\n",
        "  if stop_word:\n",
        "    for stop in stop_word:\n",
        "      text = re.sub(rf\"\\b{stop}\\b\", \"\", text)\n",
        "\n",
        "  # 15. 특수문자 제거 (허용: 한글, 공백, ~!?...)\n",
        "  num_to_kor = ['영', '일', '이', '삼', '사', '오', '육', '칠', '팔', '구']\n",
        "  tags = list(dict.fromkeys(re.findall(r'<[^<>]*>', text)))\n",
        "  for i, tag in enumerate(tags):\n",
        "    placeholder = f\"태그{num_to_kor[i]}태\"\n",
        "    text = text.replace(tag, placeholder)\n",
        "\n",
        "  text = re.sub(r\"[^가-힣 ~!?;\\.]\", \"\", text)\n",
        "\n",
        "  for i, tag in enumerate(tags):\n",
        "    placeholder = f\"태그{num_to_kor[i]}태\"\n",
        "    text = text.replace(placeholder, tag)\n",
        "\n",
        "  # 16. 공백 여러개 → 하나\n",
        "  text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "\n",
        "  # 17. 빈 문자열 → np.nan\n",
        "  if text == \"\" or text == \" \":\n",
        "      return np.nan\n",
        "  if not re.search(r\"[가-힣]|<[^<>]+>|^(; ?)+$\", text):\n",
        "    return np.nan\n",
        "\n",
        "  return text"
      ],
      "metadata": {
        "id": "TcTLgnm6teuK"
      },
      "execution_count": 572,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "special_tokens = [\n",
        "    \"<good>\",\n",
        "    \"<bad>\",\n",
        "    \"<profanity>\",\n",
        "    \"<SadToken>\",\n",
        "    \"<HappyToken>\",\n",
        "    \"<filter>\",\n",
        "    \"<zz>\",\n",
        "    \"<hh>\",\n",
        "    \"<NormalToken>\"\n",
        "]"
      ],
      "metadata": {
        "id": "KGXED5okTJz3"
      },
      "execution_count": 498,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "xkksKUKwUvkT"
      },
      "execution_count": 574,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "w-RppqVNeuSk",
        "outputId": "109638ce-3870-486e-fba3-257687fb9d96"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              id                                           document  label\n",
              "0        9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
              "1        3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
              "2       10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
              "3        9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
              "4        6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1\n",
              "...          ...                                                ...    ...\n",
              "149995   6222902                                인간이 문제지.. 소는 뭔죄인가..      0\n",
              "149996   8549745                                      평점이 너무 낮아서...      1\n",
              "149997   9311800                    이게 뭐요? 한국인은 거들먹거리고 필리핀 혼혈은 착하다?      0\n",
              "149998   2376369                        청춘 영화의 최고봉.방황과 우울했던 날들의 자화상      1\n",
              "149999   9619869                           한국 영화 최초로 수간하는 내용이 담긴 영화      0\n",
              "\n",
              "[149995 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e2761512-2059-49f8-b43a-f630c9bd7691\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9976970</td>\n",
              "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3819312</td>\n",
              "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10265843</td>\n",
              "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9045019</td>\n",
              "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6483659</td>\n",
              "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149995</th>\n",
              "      <td>6222902</td>\n",
              "      <td>인간이 문제지.. 소는 뭔죄인가..</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149996</th>\n",
              "      <td>8549745</td>\n",
              "      <td>평점이 너무 낮아서...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149997</th>\n",
              "      <td>9311800</td>\n",
              "      <td>이게 뭐요? 한국인은 거들먹거리고 필리핀 혼혈은 착하다?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149998</th>\n",
              "      <td>2376369</td>\n",
              "      <td>청춘 영화의 최고봉.방황과 우울했던 날들의 자화상</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149999</th>\n",
              "      <td>9619869</td>\n",
              "      <td>한국 영화 최초로 수간하는 내용이 담긴 영화</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>149995 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e2761512-2059-49f8-b43a-f630c9bd7691')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e2761512-2059-49f8-b43a-f630c9bd7691 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e2761512-2059-49f8-b43a-f630c9bd7691');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-aac8f5fe-cd24-4d92-836c-41f8cbb2008e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-aac8f5fe-cd24-4d92-836c-41f8cbb2008e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-aac8f5fe-cd24-4d92-836c-41f8cbb2008e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_dcb814ad-15a5-42c9-a657-0e5590a52eb6\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('train')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_dcb814ad-15a5-42c9-a657-0e5590a52eb6 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('train');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train=train[:30000]"
      ],
      "metadata": {
        "id": "zkv0RGdCcEEf"
      },
      "execution_count": 575,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "eNZoqp_yeW83"
      },
      "execution_count": 576,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test=test[:10000]"
      ],
      "metadata": {
        "id": "1qrJkVdZfSVl"
      },
      "execution_count": 577,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total=pd.concat([train,test],axis=0)"
      ],
      "metadata": {
        "id": "DLuS3KGtfbD3"
      },
      "execution_count": 578,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total['document2']=total['document'].map(custom_preprocess)"
      ],
      "metadata": {
        "id": "53petsJYfnFr"
      },
      "execution_count": 579,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train=total[:30000].copy()\n",
        "test=total[30000:].copy()"
      ],
      "metadata": {
        "id": "AKhhuTG5op_f"
      },
      "execution_count": 582,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.dropna(inplace=True)\n",
        "test.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "SoK_8SK_pYYH"
      },
      "execution_count": 583,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "Fjf4I6yLp4b_",
        "outputId": "ea994d4a-ce63-4287-f51a-d0e75f7d3948"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id           0\n",
              "document     0\n",
              "label        0\n",
              "document2    0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>document</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>document2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def select_label(group):\n",
        "  counts = group.value_counts()\n",
        "  if len(counts) == 1:\n",
        "    return counts.index[0]  # label이 하나만 존재 → 그 값 반환\n",
        "  elif counts[1] > counts[0]:\n",
        "    return 1  # label 1이 더 많으면 1 반환\n",
        "  elif counts[1] < counts[0]:\n",
        "    return 0  # label 0이 더 많으면 0 반환\n",
        "  else:\n",
        "    return random.choice([0,1])  # 동점이면 랜덤 선택\n",
        "\n",
        "# document2 기준으로 groupby 후 label 선택\n",
        "train_re = train.groupby('document2', as_index=False).agg({'label': select_label})\n",
        "test_re = test.groupby('document2', as_index=False).agg({'label' : select_label})"
      ],
      "metadata": {
        "id": "Nwed_7ceofF0"
      },
      "execution_count": 651,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_length(text):\n",
        "    # 1. ... → 특수 토큰으로 임시 치환\n",
        "    text = re.sub(r\"\\.{3}\", \"TRIPLE_DOT\", text)\n",
        "\n",
        "    # 2. <...> → 특수 토큰으로 임시 치환\n",
        "    text = re.sub(r\"<[^<>]*>\", \"TAG\", text)\n",
        "\n",
        "    # 3. 특수 토큰 개수 카운트\n",
        "    num_triple_dot = text.count(\"TRIPLE_DOT\")\n",
        "    num_tag = text.count(\"TAG\")\n",
        "\n",
        "    # 4. 임시 토큰 제거 후 나머지 글자 카운트\n",
        "    text_cleaned = text.replace(\"TRIPLE_DOT\", \"\").replace(\"TAG\", \"\")\n",
        "    length_rest = len(text_cleaned)\n",
        "\n",
        "    length_no_space = len(text_cleaned.replace(\" \", \"\"))\n",
        "\n",
        "    if length_no_space == 1:\n",
        "      length_rest=1\n",
        "\n",
        "    # 5. 최종 길이 = 특수토큰 개수 + 나머지 글자 개수\n",
        "    return num_triple_dot + num_tag + length_rest"
      ],
      "metadata": {
        "id": "pHGp4n70qgBq"
      },
      "execution_count": 367,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_re['length']=train_re['document2'].apply(lambda x : custom_length(x))\n",
        "test_re['length']=test_re['document2'].apply(lambda x : custom_length(x))"
      ],
      "metadata": {
        "id": "Arrg5DCwVLbX"
      },
      "execution_count": 652,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_length(train_re):\n",
        "    min_len = train_re['length'].min()\n",
        "    max_len = train_re['length'].max()\n",
        "    mean_len = int(train_re['length'].mean())\n",
        "\n",
        "    print(\"문장의 최단 길이:\", min_len)\n",
        "    print(\"문장의 최장 길이:\", max_len)\n",
        "    print(\"문장의 평균 길이:\", mean_len)\n",
        "\n",
        "    # 각 길이별 count\n",
        "    sentence_length = train_re['length'].value_counts().sort_index()\n",
        "\n",
        "    # 배열 초기화\n",
        "    sentence_length_arr = np.zeros(max_len, dtype=int)\n",
        "    for length, count in sentence_length.items():\n",
        "        sentence_length_arr[length - 1] = count  # index 보정\n",
        "\n",
        "    # 시각화\n",
        "    plt.bar(range(1, max_len + 1), sentence_length_arr, width=1.0)\n",
        "    plt.title(\"Sentence Length Distribution\")\n",
        "    plt.xlabel(\"Sentence Length\")\n",
        "    plt.ylabel(\"Count\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "CJRIitTDrOxP"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analyze_length(train_re)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "id": "Bl39IuY3rRYL",
        "outputId": "a6daedb6-20d3-4df2-bc40-3241882d278e"
      },
      "execution_count": 346,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문장의 최단 길이: 1\n",
            "문장의 최장 길이: 143\n",
            "문장의 평균 길이: 32\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "analyze_length(test_re)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "id": "Kmcjz_KErYKT",
        "outputId": "009dd2d2-87f4-489e-c729-9254c3c67db9"
      },
      "execution_count": 347,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문장의 최단 길이: 1\n",
            "문장의 최장 길이: 140\n",
            "문장의 평균 길이: 32\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(train_re['length']>100).sum()/len(train_re)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDbyzwuUVRkr",
        "outputId": "b84a986f-2a11-4060-f2c3-135fd9d675e0"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.0494592004381161)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len=100"
      ],
      "metadata": {
        "id": "N37jftkDroBp"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min_len=2"
      ],
      "metadata": {
        "id": "SxApLQHca62D"
      },
      "execution_count": 667,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_re = train_re[(train_re['length'] >= min_len) & (train_re['length'] <= max_len)].reset_index(drop=True)\n",
        "test_re = test_re[(test_re['length'] >= min_len) & (test_re['length'] <= max_len)].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "8Z4Maf7t8mYd"
      },
      "execution_count": 654,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "09bm6i-UsCdP"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_train_valid_df(df, valid_size=0.2, random_state=42):\n",
        "    train_df, valid_df = train_test_split(\n",
        "        df, test_size=valid_size, random_state=random_state, stratify=df['label']\n",
        "    )\n",
        "    return train_df, valid_df"
      ],
      "metadata": {
        "id": "ILM_fWPNd9fp"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, valid_df = split_train_valid_df(train_re, random_state=42)"
      ],
      "metadata": {
        "id": "GiO5VAISsEY5"
      },
      "execution_count": 656,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sentencepiece as spm\n",
        "import os\n",
        "temp_file = \"./train.temp\"\n",
        "\n",
        "vocab_size = 9000\n",
        "\n",
        "with open(temp_file, 'w') as f:\n",
        "    for row in train_df['document2']:   # 이전에 나왔던 정제했던 corpus를 활용해서 진행해야 합니다.\n",
        "        f.write(str(row) + '\\n')\n",
        "\n",
        "spm.SentencePieceTrainer.Train(\n",
        "    '--input={} --model_prefix=korean_spm --vocab_size={} --user_defined_symbols={} --model_type=bpe'.format(\n",
        "        temp_file,\n",
        "        vocab_size,\n",
        "        ','.join(special_tokens)\n",
        "    )\n",
        ")\n",
        "#위 Train에서  --model_type = unigram이 디폴트 적용되어 있습니다. --model_type = bpe로 옵션을 주어 변경할 수 있습니다."
      ],
      "metadata": {
        "id": "sdOYqLp7ej9W"
      },
      "execution_count": 589,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_re['document2'][500]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "rXLHyZxKt8mQ",
        "outputId": "1788211d-db4f-45df-c68f-bda91ca75a4c"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<zz> 전우치싫어하는 사람 말해라 다 혼줄을 내줄거야'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = spm.SentencePieceProcessor()\n",
        "s.Load('korean_spm.model')\n",
        "\n",
        "# SentencePiece를 활용한 sentence -> encoding\n",
        "tokensIDs = s.EncodeAsIds(train_re['document2'][700])\n",
        "print(tokensIDs)\n",
        "\n",
        "# SentencePiece를 활용한 sentence -> encoded pieces\n",
        "print(s.SampleEncodeAsPieces(train_re['document2'][700],10, 0.1))\n",
        "\n",
        "# SentencePiece를 활용한 encoding -> sentence 복원\n",
        "print(s.DecodeIds(tokensIDs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zi_UDUnAelqe",
        "outputId": "ddf5b2a9-a36b-4ba8-c4db-56298ef00b75"
      },
      "execution_count": 590,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[47, 7815, 259, 1559, 388]\n",
            "['▁가', '식', '없는', '▁', '훌륭', '한', '▁영화다']\n",
            "가식없는 훌륭한 영화다\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sp_tokenize(s, corpus):\n",
        "  tensor = []\n",
        "\n",
        "  for sen in corpus:\n",
        "      tensor.append(s.EncodeAsIds(sen))\n",
        "\n",
        "  with open(\"./korean_spm.vocab\", 'r') as f:\n",
        "      vocab = f.readlines()\n",
        "\n",
        "  word_index = {}\n",
        "  index_word = {}\n",
        "\n",
        "  for idx, line in enumerate(vocab):\n",
        "      word = line.split(\"\\t\")[0]\n",
        "\n",
        "      word_index.update({word:idx})\n",
        "      index_word.update({idx:word})\n",
        "\n",
        "  tensor = [[9000 if token == 0 else token for token in seq] for seq in tensor]\n",
        "\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "  tensor,\n",
        "  maxlen=max_len,\n",
        "  padding='post',\n",
        "  truncating='post'\n",
        ")\n",
        "\n",
        "  return tensor, word_index, index_word"
      ],
      "metadata": {
        "id": "fHhcTEGwxn0j"
      },
      "execution_count": 501,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_tf, sword_index, sindex_word = sp_tokenize(s,train_df['document2'])\n",
        "valid_tf, _, _ = sp_tokenize(s,valid_df['document2'])\n",
        "test_tf, _, _ = sp_tokenize(s,test_re['document2'])"
      ],
      "metadata": {
        "id": "paC9e0900nu7"
      },
      "execution_count": 502,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_tf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wascXBFAGFxH",
        "outputId": "cb7a4960-277c-40d3-ca14-5bae3df8265f"
      },
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 221,  291,   13, ...,    0,    0,    0],\n",
              "       [ 184,  719,  172, ...,    0,    0,    0],\n",
              "       [  13,   45, 1406, ...,    0,    0,    0],\n",
              "       ...,\n",
              "       [  13,   38, 3553, ...,    0,    0,    0],\n",
              "       [1946,  306, 2947, ...,    0,    0,    0],\n",
              "       [2263,  350,   29, ...,    0,    0,    0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 232
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_tf,\n",
        "    train_df['label']\n",
        ")).shuffle(buffer_size=len(train_df),seed=42).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "valid_dataset = tf.data.Dataset.from_tensor_slices((valid_tf,\n",
        "    valid_df['label']\n",
        ")).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_tf, test_re['label'])).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "wXkoyWNwdgih"
      },
      "execution_count": 503,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam, AdamW\n",
        "\n",
        "lr = 5e-4\n",
        "\n",
        "vocab_size = 9001\n",
        "embedding_dim = 128\n",
        "lstm_units = 64\n",
        "\n",
        "input_ = Input(shape=(None,), name='input')\n",
        "x = Embedding(input_dim=vocab_size, output_dim=embedding_dim, mask_zero=True)(input_)\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "# x = LSTM(lstm_units, return_sequences=True)(x)\n",
        "# x = LSTM(lstm_units, return_sequences=False)(x)\n",
        "\n",
        "#x = Bidirectional(LSTM(lstm_units, return_sequences=False))(x)\n",
        "x = Bidirectional(LSTM(lstm_units, return_sequences=False))(x)\n",
        "\n",
        "\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs=input_, outputs=output)\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=lr), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "id": "Gg0FyVN0dSFL",
        "outputId": "74bacf59-5882-4bf6-9118-a1981c738a9b"
      },
      "execution_count": 600,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_48\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_48\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_50        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) │  \u001b[38;5;34m1,152,128\u001b[0m │ input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_132         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ embedding_50[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal_48        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_67 (\u001b[38;5;33mLSTM\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m49,408\u001b[0m │ dropout_132[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ not_equal_48[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_133         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ lstm_67[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_97 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m4,160\u001b[0m │ dropout_133[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_134         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_97[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_98 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dropout_134[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_50        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,152,128</span> │ input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_132         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal_48        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_67 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │ dropout_132[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ not_equal_48[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_133         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_67[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_97 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ dropout_133[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_134         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_97[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_98 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dropout_134[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,205,761\u001b[0m (4.60 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,205,761</span> (4.60 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,205,761\u001b[0m (4.60 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,205,761</span> (4.60 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
      ],
      "metadata": {
        "id": "TSI60JeldpjJ"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True, verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1)"
      ],
      "metadata": {
        "id": "rKmM934idssc"
      },
      "execution_count": 505,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=valid_dataset,\n",
        "    epochs=20,\n",
        "    callbacks=[early_stop, reduce_lr]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oX0WXvxQdupp",
        "outputId": "3695fddd-352d-4c57-959b-4f092d438733"
      },
      "execution_count": 506,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.6178 - loss: 0.6381 - val_accuracy: 0.8151 - val_loss: 0.4094 - learning_rate: 5.0000e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.8809 - loss: 0.3025 - val_accuracy: 0.8264 - val_loss: 0.3965 - learning_rate: 5.0000e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - accuracy: 0.9192 - loss: 0.2222 - val_accuracy: 0.8228 - val_loss: 0.4257 - learning_rate: 5.0000e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9407 - loss: 0.1730\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.9406 - loss: 0.1731 - val_accuracy: 0.8177 - val_loss: 0.4616 - learning_rate: 5.0000e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.9539 - loss: 0.1381 - val_accuracy: 0.8114 - val_loss: 0.5697 - learning_rate: 2.5000e-04\n",
            "Epoch 5: early stopping\n",
            "Restoring model weights from the end of the best epoch: 2.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_dataset) #vocab 9000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gliiXF_CJwR0",
        "outputId": "1f2a8ed5-85a5-4ab9-e572-aab18c0fab98"
      },
      "execution_count": 430,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8281 - loss: 0.4004\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4089818596839905, 0.8213071227073669]"
            ]
          },
          "metadata": {},
          "execution_count": 430
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_dataset) #vocab 12000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oh1IbP2vdCwX",
        "outputId": "297fca80-ffa4-4851-8aa6-9767b2c7021c"
      },
      "execution_count": 442,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8255 - loss: 0.4003\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4085405468940735, 0.8183916211128235]"
            ]
          },
          "metadata": {},
          "execution_count": 442
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_dataset) #vocab 7000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdkvRj_5dTJQ",
        "outputId": "8e6c81e4-307f-458a-bc3f-b9d615b355d9"
      },
      "execution_count": 463,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8272 - loss: 0.3942\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.402022123336792, 0.8198493719100952]"
            ]
          },
          "metadata": {},
          "execution_count": 463
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_dataset) #vocab 9000 bpe !?"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CZfKrDZdy1W",
        "outputId": "8c8beb19-45bc-42a0-dd0c-b38930d15871"
      },
      "execution_count": 472,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8245 - loss: 0.3978\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4021438658237457, 0.8228862881660461]"
            ]
          },
          "metadata": {},
          "execution_count": 472
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_dataset) #vocab 12000 bpe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4m_nh9kgeP25",
        "outputId": "b1fea56d-294a-4dc1-fccf-a6b89658673d"
      },
      "execution_count": 481,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8219 - loss: 0.4051\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.40881815552711487, 0.8199708461761475]"
            ]
          },
          "metadata": {},
          "execution_count": 481
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "bpe가 unigram보다 소폭 오름.\n",
        "gpe 연산이 재현성이 없음."
      ],
      "metadata": {
        "id": "lI2FwLcOeVve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sword_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8SIjIVGe00f",
        "outputId": "320c30a9-969d-4694-c37f-08e1a36660c3"
      },
      "execution_count": 508,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<unk>': 0,\n",
              " '<s>': 1,\n",
              " '</s>': 2,\n",
              " '<good>': 3,\n",
              " '<bad>': 4,\n",
              " '<profanity>': 5,\n",
              " '<SadToken>': 6,\n",
              " '<HappyToken>': 7,\n",
              " '<filter>': 8,\n",
              " '<zz>': 9,\n",
              " '<hh>': 10,\n",
              " '<NormalToken>': 11,\n",
              " '..': 12,\n",
              " '...': 13,\n",
              " '영화': 14,\n",
              " '▁영화': 15,\n",
              " '▁이': 16,\n",
              " '▁아': 17,\n",
              " '▁보': 18,\n",
              " '▁재': 19,\n",
              " '▁그': 20,\n",
              " '▁정': 21,\n",
              " '▁나': 22,\n",
              " '는데': 23,\n",
              " '니다': 24,\n",
              " '너무': 25,\n",
              " '▁없': 26,\n",
              " '▁좋': 27,\n",
              " '▁다': 28,\n",
              " '▁너무': 29,\n",
              " '▁진': 30,\n",
              " '▁감': 31,\n",
              " '▁재미': 32,\n",
              " '▁최': 33,\n",
              " '▁연': 34,\n",
              " '▁사': 35,\n",
              " '▁내': 36,\n",
              " '하고': 37,\n",
              " '▁지': 38,\n",
              " '▁정말': 39,\n",
              " '▁어': 40,\n",
              " '▁안': 41,\n",
              " '▁만': 42,\n",
              " '네요': 43,\n",
              " '▁한': 44,\n",
              " '▁스': 45,\n",
              " '▁시': 46,\n",
              " '▁가': 47,\n",
              " '▁있': 48,\n",
              " '으로': 49,\n",
              " '▁평': 50,\n",
              " '지만': 51,\n",
              " '▁봤': 52,\n",
              " '▁하': 53,\n",
              " '▁기': 54,\n",
              " '▁재밌': 55,\n",
              " '▁진짜': 56,\n",
              " '에서': 57,\n",
              " '▁대': 58,\n",
              " '▁최고': 59,\n",
              " '▁연기': 60,\n",
              " '▁마': 61,\n",
              " '▁전': 62,\n",
              " '▁일': 63,\n",
              " '▁잘': 64,\n",
              " '▁여': 65,\n",
              " '어요': 66,\n",
              " '하는': 67,\n",
              " '▁수': 68,\n",
              " '▁주': 69,\n",
              " '▁평점': 70,\n",
              " '▁모': 71,\n",
              " '▁생': 72,\n",
              " '▁...': 73,\n",
              " '▁않': 74,\n",
              " '▁더': 75,\n",
              " '▁개': 76,\n",
              " '▁배': 77,\n",
              " '드라': 78,\n",
              " '▁오': 79,\n",
              " '▁제': 80,\n",
              " '토리': 81,\n",
              " '이다': 82,\n",
              " '▁인': 83,\n",
              " '드라마': 84,\n",
              " '▁말': 85,\n",
              " '▁무': 86,\n",
              " '습니다': 87,\n",
              " '▁소': 88,\n",
              " '▁스토리': 89,\n",
              " '▁남': 90,\n",
              " '하다': 91,\n",
              " '▁감동': 92,\n",
              " '▁알': 93,\n",
              " '▁본': 94,\n",
              " '▁생각': 95,\n",
              " '▁유': 96,\n",
              " '▁못': 97,\n",
              " '▁미': 98,\n",
              " '▁느': 99,\n",
              " '▁보고': 100,\n",
              " '▁별': 101,\n",
              " '▁자': 102,\n",
              " '▁볼': 103,\n",
              " '들이': 104,\n",
              " '▁지루': 105,\n",
              " '었다': 106,\n",
              " '▁쓰': 107,\n",
              " '▁장': 108,\n",
              " '▁드라마': 109,\n",
              " '까지': 110,\n",
              " '▁그냥': 111,\n",
              " '▁비': 112,\n",
              " '▁역': 113,\n",
              " '▁많': 114,\n",
              " '▁만들': 115,\n",
              " '이라': 116,\n",
              " '하게': 117,\n",
              " '▁작': 118,\n",
              " '▁재미있': 119,\n",
              " '▁우': 120,\n",
              " '▁중': 121,\n",
              " '▁완': 122,\n",
              " '▁공': 123,\n",
              " '보다': 124,\n",
              " '▁배우': 125,\n",
              " '▁감독': 126,\n",
              " '▁부': 127,\n",
              " '▁명': 128,\n",
              " '▁끝': 129,\n",
              " '레기': 130,\n",
              " '▁뭐': 131,\n",
              " '▁내용': 132,\n",
              " '해서': 133,\n",
              " '렇게': 134,\n",
              " '▁년': 135,\n",
              " '▁웃': 136,\n",
              " '같은': 137,\n",
              " '▁애': 138,\n",
              " '▁사람': 139,\n",
              " '면서': 140,\n",
              " '▁사랑': 141,\n",
              " '▁보는': 142,\n",
              " '▁다시': 143,\n",
              " '▁재미없': 144,\n",
              " '▁!': 145,\n",
              " '▁고': 146,\n",
              " '▁쓰레기': 147,\n",
              " '▁조': 148,\n",
              " '다는': 149,\n",
              " '▁반': 150,\n",
              " '액션': 151,\n",
              " '▁되': 152,\n",
              " '▁해': 153,\n",
              " '▁이거': 154,\n",
              " '적인': 155,\n",
              " '▁싶': 156,\n",
              " '▁신': 157,\n",
              " '▁아니': 158,\n",
              " '▁영화를': 159,\n",
              " '지막': 160,\n",
              " '▁저': 161,\n",
              " '▁예': 162,\n",
              " '▁분': 163,\n",
              " '▁시간': 164,\n",
              " '▁처': 165,\n",
              " '보고': 166,\n",
              " '▁실': 167,\n",
              " '▁이건': 168,\n",
              " '▁완전': 169,\n",
              " '▁좋은': 170,\n",
              " '▁봐': 171,\n",
              " '▁매': 172,\n",
              " '▁액션': 173,\n",
              " '▁살': 174,\n",
              " '▁영': 175,\n",
              " '▁마지막': 176,\n",
              " '▁세': 177,\n",
              " '▁봤는데': 178,\n",
              " '▁상': 179,\n",
              " '▁없는': 180,\n",
              " '▁영화가': 181,\n",
              " '으면': 182,\n",
              " '▁작품': 183,\n",
              " '▁눈': 184,\n",
              " '▁최고의': 185,\n",
              " '▁도': 186,\n",
              " '▁좋아': 187,\n",
              " '들의': 188,\n",
              " '라고': 189,\n",
              " '▁난': 190,\n",
              " '▁기대': 191,\n",
              " '▁원': 192,\n",
              " '▁노': 193,\n",
              " '▁내가': 194,\n",
              " '▁이렇게': 195,\n",
              " '하지': 196,\n",
              " '▁바': 197,\n",
              " '▁영화는': 198,\n",
              " '▁일점': 199,\n",
              " '입니다': 200,\n",
              " '▁지금': 201,\n",
              " '▁거': 202,\n",
              " '▁넘': 203,\n",
              " '▁편': 204,\n",
              " '▁것': 205,\n",
              " '▁로': 206,\n",
              " '▁십': 207,\n",
              " '▁성': 208,\n",
              " '▁처음': 209,\n",
              " '세요': 210,\n",
              " '았다': 211,\n",
              " '▁최악': 212,\n",
              " '▁몰': 213,\n",
              " '▁후': 214,\n",
              " '▁있는': 215,\n",
              " '▁결': 216,\n",
              " '▁코': 217,\n",
              " '▁역시': 218,\n",
              " '▁돈': 219,\n",
              " '▁불': 220,\n",
              " '적이': 221,\n",
              " '▁없다': 222,\n",
              " '▁의': 223,\n",
              " '▁죽': 224,\n",
              " '했다': 225,\n",
              " '▁모르': 226,\n",
              " '▁십점': 227,\n",
              " '▁구': 228,\n",
              " '▁멋': 229,\n",
              " '야기': 230,\n",
              " '지는': 231,\n",
              " '▁추': 232,\n",
              " '▁아깝': 233,\n",
              " '▁화': 234,\n",
              " '▁연출': 235,\n",
              " '▁평점이': 236,\n",
              " '▁김': 237,\n",
              " '겠다': 238,\n",
              " '▁이게': 239,\n",
              " '▁한국': 240,\n",
              " '▁할': 241,\n",
              " '다가': 242,\n",
              " '이나': 243,\n",
              " '인공': 244,\n",
              " '▁이런': 245,\n",
              " '▁점': 246,\n",
              " '▁나오': 247,\n",
              " '▁허': 248,\n",
              " '어서': 249,\n",
              " '▁명작': 250,\n",
              " '▁별로': 251,\n",
              " '▁강': 252,\n",
              " '▁심': 253,\n",
              " '인데': 254,\n",
              " '합니다': 255,\n",
              " '▁초': 256,\n",
              " '▁하는': 257,\n",
              " '▁재밌게': 258,\n",
              " '▁극': 259,\n",
              " '▁느낌': 260,\n",
              " '▁현': 261,\n",
              " '▁기억': 262,\n",
              " '▁괜': 263,\n",
              " '▁캐': 264,\n",
              " '들은': 265,\n",
              " '한다': 266,\n",
              " '▁아름': 267,\n",
              " '▁두': 268,\n",
              " '부터': 269,\n",
              " '없는': 270,\n",
              " '라는': 271,\n",
              " '에게': 272,\n",
              " '▁왜': 273,\n",
              " '▁음': 274,\n",
              " '있는': 275,\n",
              " '▁많이': 276,\n",
              " '▁에': 277,\n",
              " '정도': 278,\n",
              " '▁같': 279,\n",
              " '적으로': 280,\n",
              " '▁당': 281,\n",
              " '대로': 282,\n",
              " '▁이영화': 283,\n",
              " '▁따': 284,\n",
              " '▁했': 285,\n",
              " '연기': 286,\n",
              " '▁이야기': 287,\n",
              " '▁짜': 288,\n",
              " '▁꼭': 289,\n",
              " '▁발': 290,\n",
              " '▁만든': 291,\n",
              " '지도': 292,\n",
              " '▁잼': 293,\n",
              " '▁아이': 294,\n",
              " '▁잔': 295,\n",
              " '▁일본': 296,\n",
              " '▁관': 297,\n",
              " '다고': 298,\n",
              " '주는': 299,\n",
              " '되는': 300,\n",
              " '▁아까': 301,\n",
              " '▁울': 302,\n",
              " '▁줄': 303,\n",
              " '▁이해': 304,\n",
              " '▁뭔': 305,\n",
              " '▁엄': 306,\n",
              " '▁요': 307,\n",
              " '▁위': 308,\n",
              " '▁장면': 309,\n",
              " '▁포': 310,\n",
              " '▁~': 311,\n",
              " '을까': 312,\n",
              " '▁여자': 313,\n",
              " '▁좋았': 314,\n",
              " '▁졸': 315,\n",
              " '리는': 316,\n",
              " '하나': 317,\n",
              " '▁없고': 318,\n",
              " '▁공포': 319,\n",
              " '▁유치': 320,\n",
              " '▁동': 321,\n",
              " '사람': 322,\n",
              " '▁하나': 323,\n",
              " '▁괜찮': 324,\n",
              " '▁귀': 325,\n",
              " '▁삼': 326,\n",
              " '▁특': 327,\n",
              " '드는': 328,\n",
              " '▁아깝다': 329,\n",
              " '▁들': 330,\n",
              " '필요': 331,\n",
              " '하기': 332,\n",
              " '▁같은': 333,\n",
              " '만에': 334,\n",
              " '▁가장': 335,\n",
              " '▁보면': 336,\n",
              " '▁?': 337,\n",
              " '▁막': 338,\n",
              " '▁보여': 339,\n",
              " '▁슬': 340,\n",
              " '▁흥': 341,\n",
              " '▁가슴': 342,\n",
              " '▁박': 343,\n",
              " '▁몰입': 344,\n",
              " '▁마음': 345,\n",
              " '배우': 346,\n",
              " '▁힘': 347,\n",
              " '▁애니': 348,\n",
              " '▁걸': 349,\n",
              " '아서': 350,\n",
              " '▁누': 351,\n",
              " '▁아닌': 352,\n",
              " '나는': 353,\n",
              " '없다': 354,\n",
              " '재미': 355,\n",
              " '▁리': 356,\n",
              " '▁서': 357,\n",
              " '인가': 358,\n",
              " '▁반전': 359,\n",
              " '▁볼만': 360,\n",
              " '▁표': 361,\n",
              " '▁긴': 362,\n",
              " '▁말이': 363,\n",
              " '▁인생': 364,\n",
              " '가는': 365,\n",
              " '었는데': 366,\n",
              " '▁낮': 367,\n",
              " '▁소재': 368,\n",
              " '▁계': 369,\n",
              " '▁존': 370,\n",
              " '봐도': 371,\n",
              " '미디': 372,\n",
              " '▁극장': 373,\n",
              " '▁우리': 374,\n",
              " '▁단': 375,\n",
              " '▁방': 376,\n",
              " '였다': 377,\n",
              " '인지': 378,\n",
              " '▁설': 379,\n",
              " '▁솔': 380,\n",
              " '▁결말': 381,\n",
              " '▁근': 382,\n",
              " '▁높': 383,\n",
              " '▁망': 384,\n",
              " '없이': 385,\n",
              " '▁매력': 386,\n",
              " '▁억': 387,\n",
              " '니까': 388,\n",
              " '▁음악': 389,\n",
              " '▁영화다': 390,\n",
              " '▁드': 391,\n",
              " '것도': 392,\n",
              " '▁충': 393,\n",
              " '▁현실': 394,\n",
              " '▁주인공': 395,\n",
              " '▁건': 396,\n",
              " '▁선': 397,\n",
              " '▁남자': 398,\n",
              " '▁만들어': 399,\n",
              " '▁절': 400,\n",
              " '▁참': 401,\n",
              " '구나': 402,\n",
              " '▁그런': 403,\n",
              " '는지': 404,\n",
              " '▁모든': 405,\n",
              " '▁빠': 406,\n",
              " '▁스릴': 407,\n",
              " '▁아무': 408,\n",
              " '릭터': 409,\n",
              " '재밌': 410,\n",
              " '▁이제': 411,\n",
              " '▁짜증': 412,\n",
              " '는다': 413,\n",
              " '▁눈물': 414,\n",
              " '▁솔직': 415,\n",
              " '▁뻔': 416,\n",
              " '다니': 417,\n",
              " '최고': 418,\n",
              " '▁봐도': 419,\n",
              " '▁아직': 420,\n",
              " '▁영상': 421,\n",
              " '▁하고': 422,\n",
              " '스러': 423,\n",
              " '▁짱': 424,\n",
              " '이고': 425,\n",
              " '▁정도': 426,\n",
              " '▁아름다': 427,\n",
              " '었던': 428,\n",
              " '▁머': 429,\n",
              " '메이': 430,\n",
              " '▁한번': 431,\n",
              " '▁순': 432,\n",
              " '▁보기': 433,\n",
              " '▁원작': 434,\n",
              " '▁간': 435,\n",
              " '▁프': 436,\n",
              " '▁보지': 437,\n",
              " '▁추천': 438,\n",
              " '▁;': 439,\n",
              " '▁집': 440,\n",
              " '▁솔직히': 441,\n",
              " '스럽': 442,\n",
              " '아요': 443,\n",
              " '에는': 444,\n",
              " '스터': 445,\n",
              " '▁속': 446,\n",
              " '리고': 447,\n",
              " '하면': 448,\n",
              " '▁달': 449,\n",
              " '▁맞': 450,\n",
              " '▁끝까지': 451,\n",
              " '리즈': 452,\n",
              " '▁대한': 453,\n",
              " '▁필요': 454,\n",
              " '하지만': 455,\n",
              " '▁문': 456,\n",
              " '▁새': 457,\n",
              " '▁적': 458,\n",
              " '▁긴장': 459,\n",
              " '▁많은': 460,\n",
              " '▁캐릭터': 461,\n",
              " '▁돌': 462,\n",
              " '▁공감': 463,\n",
              " '▁여운': 464,\n",
              " '▁욕': 465,\n",
              " '▁아주': 466,\n",
              " '▁게': 467,\n",
              " '나서': 468,\n",
              " '▁개봉': 469,\n",
              " '▁인간': 470,\n",
              " '때문': 471,\n",
              " '려고': 472,\n",
              " '리가': 473,\n",
              " '떨어': 474,\n",
              " '보는': 475,\n",
              " '▁계속': 476,\n",
              " '▁코미디': 477,\n",
              " '▁과': 478,\n",
              " '▁열': 479,\n",
              " '▁올': 480,\n",
              " '나오': 481,\n",
              " '▁이상': 482,\n",
              " '지고': 483,\n",
              " '▁수준': 484,\n",
              " '▁피': 485,\n",
              " '스트': 486,\n",
              " '었음': 487,\n",
              " '▁억지': 488,\n",
              " '▁차': 489,\n",
              " '▁파': 490,\n",
              " '▁호': 491,\n",
              " '▁엄청': 492,\n",
              " '▁갈': 493,\n",
              " '▁엉': 494,\n",
              " '더라': 495,\n",
              " '준다': 496,\n",
              " '▁근데': 497,\n",
              " '▁이걸': 498,\n",
              " '▁배우들': 499,\n",
              " '▁번': 500,\n",
              " '중에': 501,\n",
              " '▁제목': 502,\n",
              " '▁재미도': 503,\n",
              " '▁찍': 504,\n",
              " '▁친': 505,\n",
              " '▁흥미': 506,\n",
              " '▁최악의': 507,\n",
              " '▁몇': 508,\n",
              " '이는': 509,\n",
              " '처럼': 510,\n",
              " '▁전혀': 511,\n",
              " '▁외': 512,\n",
              " '을때': 513,\n",
              " '이지': 514,\n",
              " '▁웃기': 515,\n",
              " '▁듯': 516,\n",
              " '타임': 517,\n",
              " '했던': 518,\n",
              " '▁먹': 519,\n",
              " '밖에': 520,\n",
              " '수록': 521,\n",
              " '▁잔잔': 522,\n",
              " '▁연기력': 523,\n",
              " '▁즐': 524,\n",
              " '다면': 525,\n",
              " '▁대단': 526,\n",
              " '▁레': 527,\n",
              " '된다': 528,\n",
              " '수가': 529,\n",
              " '▁대박': 530,\n",
              " '▁믿': 531,\n",
              " '▁언': 532,\n",
              " '▁출': 533,\n",
              " '▁치': 534,\n",
              " '기도': 535,\n",
              " '는거': 536,\n",
              " '▁뭔가': 537,\n",
              " '▁실망': 538,\n",
              " '▁버': 539,\n",
              " '▁독': 540,\n",
              " '▁받': 541,\n",
              " '▁찾': 542,\n",
              " '▁행': 543,\n",
              " '▁베': 544,\n",
              " '지않': 545,\n",
              " '▁어디': 546,\n",
              " '▁교': 547,\n",
              " '건지': 548,\n",
              " '장면': 549,\n",
              " '▁가족': 550,\n",
              " '▁로맨': 551,\n",
              " '▁전개': 552,\n",
              " '▁영화에': 553,\n",
              " '▁천': 554,\n",
              " '생각': 555,\n",
              " '진짜': 556,\n",
              " '▁보다': 557,\n",
              " '▁재밋': 558,\n",
              " '하네요': 559,\n",
              " '▁긴장감': 560,\n",
              " '▁영화의': 561,\n",
              " '▁재밌다': 562,\n",
              " '▁답': 563,\n",
              " '▁홍': 564,\n",
              " '나라': 565,\n",
              " '▁크': 566,\n",
              " '▁나온': 567,\n",
              " '▁재미있게': 568,\n",
              " '내내': 569,\n",
              " '어도': 570,\n",
              " '이랑': 571,\n",
              " '▁않은': 572,\n",
              " '영화는': 573,\n",
              " '▁경': 574,\n",
              " '▁놀': 575,\n",
              " '▁악': 576,\n",
              " '만들': 577,\n",
              " '보면': 578,\n",
              " '전에': 579,\n",
              " '주고': 580,\n",
              " '▁나도': 581,\n",
              " '▁떨어': 582,\n",
              " '▁오랜': 583,\n",
              " '했는데': 584,\n",
              " '▁시간이': 585,\n",
              " '▁손': 586,\n",
              " '▁헐': 587,\n",
              " '▁제일': 588,\n",
              " '때문에': 589,\n",
              " '▁연기도': 590,\n",
              " '이상': 591,\n",
              " '▁않고': 592,\n",
              " '었어요': 593,\n",
              " '▁떠': 594,\n",
              " '▁메': 595,\n",
              " '▁내내': 596,\n",
              " '▁보게': 597,\n",
              " '▁알바': 598,\n",
              " '▁잼있': 599,\n",
              " '▁제작': 600,\n",
              " '▁시리즈': 601,\n",
              " '▁아름다운': 602,\n",
              " '▁잊': 603,\n",
              " '▁좀': 604,\n",
              " '▁남는': 605,\n",
              " '▁삼류': 606,\n",
              " '▁좋다': 607,\n",
              " '없고': 608,\n",
              " '▁따뜻': 609,\n",
              " '▁세상': 610,\n",
              " '▁아쉬': 611,\n",
              " '▁담': 612,\n",
              " '▁개인': 613,\n",
              " '▁느껴': 614,\n",
              " '▁표현': 615,\n",
              " '주인공': 616,\n",
              " '▁내용이': 617,\n",
              " '▁보고싶': 618,\n",
              " '▁아직도': 619,\n",
              " '▁여운이': 620,\n",
              " '▁굿': 621,\n",
              " '▁막장': 622,\n",
              " '▁부족': 623,\n",
              " '▁내용도': 624,\n",
              " '▁뭘': 625,\n",
              " '라도': 626,\n",
              " '인듯': 627,\n",
              " '적이고': 628,\n",
              " '하면서': 629,\n",
              " '▁감독의': 630,\n",
              " '▁스릴러': 631,\n",
              " '▁봐야': 632,\n",
              " '봤는데': 633,\n",
              " '▁뒤': 634,\n",
              " '▁잠': 635,\n",
              " '▁형': 636,\n",
              " '들도': 637,\n",
              " '만한': 638,\n",
              " '엔딩': 639,\n",
              " '▁정신': 640,\n",
              " '▁중간': 641,\n",
              " '▁제대로': 642,\n",
              " '▁좋았다': 643,\n",
              " '▁싸': 644,\n",
              " '▁질': 645,\n",
              " '들을': 646,\n",
              " '▁만화': 647,\n",
              " '▁통': 648,\n",
              " '▁훌': 649,\n",
              " '같다': 650,\n",
              " '리스': 651,\n",
              " '▁기분': 652,\n",
              " '▁년대': 653,\n",
              " '▁왜이': 654,\n",
              " '▁이유': 655,\n",
              " '▁국': 656,\n",
              " '▁네': 657,\n",
              " '▁앞': 658,\n",
              " '군요': 659,\n",
              " '으나': 660,\n",
              " '해요': 661,\n",
              " '▁멋진': 662,\n",
              " '▁봤다': 663,\n",
              " '▁싶다': 664,\n",
              " '▁아쉽': 665,\n",
              " '▁요즘': 666,\n",
              " '▁얼': 667,\n",
              " '감독': 668,\n",
              " '기는': 669,\n",
              " '성이': 670,\n",
              " '하네': 671,\n",
              " '▁친구': 672,\n",
              " '▁스토리도': 673,\n",
              " '▁복': 674,\n",
              " '▁와': 675,\n",
              " '▁케': 676,\n",
              " '▁탄': 677,\n",
              " '내용': 678,\n",
              " '만큼': 679,\n",
              " '에도': 680,\n",
              " '▁나름': 681,\n",
              " '▁대사': 682,\n",
              " '▁수작': 683,\n",
              " '▁너무나': 684,\n",
              " '▁만드는': 685,\n",
              " '▁모르겠': 686,\n",
              " '▁아까운': 687,\n",
              " '▁아니고': 688,\n",
              " '▁재미없다': 689,\n",
              " '▁절대': 690,\n",
              " '▁훌륭': 691,\n",
              " '▁감독이': 692,\n",
              " '▁보다가': 693,\n",
              " '▁연기가': 694,\n",
              " '▁스토리가': 695,\n",
              " '▁야': 696,\n",
              " '로운': 697,\n",
              " '시간': 698,\n",
              " '▁나와': 699,\n",
              " '▁영화였': 700,\n",
              " '▁지루하고': 701,\n",
              " '▁데': 702,\n",
              " '▁된': 703,\n",
              " '▁목': 704,\n",
              " '레이': 705,\n",
              " '▁노래': 706,\n",
              " '메이션': 707,\n",
              " '영화가': 708,\n",
              " '▁나오는': 709,\n",
              " '▁아니다': 710,\n",
              " '▁봤습니다': 711,\n",
              " '▁영화라고': 712,\n",
              " '▁니': 713,\n",
              " '▁은': 714,\n",
              " '▁카': 715,\n",
              " '▁킬': 716,\n",
              " '▁타': 717,\n",
              " '▁판': 718,\n",
              " '고싶': 719,\n",
              " '▁나는': 720,\n",
              " '▁소름': 721,\n",
              " '▁시작': 722,\n",
              " '▁유쾌': 723,\n",
              " '▁보면서': 724,\n",
              " '▁약': 725,\n",
              " '▁티': 726,\n",
              " '어야': 727,\n",
              " '점이': 728,\n",
              " '▁모습': 729,\n",
              " '▁자체': 730,\n",
              " '이라는': 731,\n",
              " '▁일점도': 732,\n",
              " '던데': 733,\n",
              " '리오': 734,\n",
              " '이가': 735,\n",
              " '진다': 736,\n",
              " '▁나왔': 737,\n",
              " '▁느끼': 738,\n",
              " '▁뻔한': 739,\n",
              " '▁시대': 740,\n",
              " '▁싶은': 741,\n",
              " '▁허접': 742,\n",
              " '았는데': 743,\n",
              " '▁괜찮은': 744,\n",
              " '▁아름답': 745,\n",
              " '▁때': 746,\n",
              " '치는': 747,\n",
              " '▁장난': 748,\n",
              " '▁진심': 749,\n",
              " '▁특히': 750,\n",
              " '스러운': 751,\n",
              " '▁마지막에': 752,\n",
              " '▁걍': 753,\n",
              " '▁디': 754,\n",
              " '▁빼': 755,\n",
              " '▁팔': 756,\n",
              " '대체': 757,\n",
              " '한테': 758,\n",
              " '▁무서': 759,\n",
              " '▁않는': 760,\n",
              " '▁이딴': 761,\n",
              " '▁전쟁': 762,\n",
              " '이라고': 763,\n",
              " '▁아니라': 764,\n",
              " '▁영화입니다': 765,\n",
              " '▁낚': 766,\n",
              " '해도': 767,\n",
              " '▁미국': 768,\n",
              " '▁진정': 769,\n",
              " '▁오랜만에': 770,\n",
              " '▁각': 771,\n",
              " '▁삶': 772,\n",
              " '▁토': 773,\n",
              " '나고': 774,\n",
              " '시길': 775,\n",
              " '▁사실': 776,\n",
              " '▁점수': 777,\n",
              " '▁출연': 778,\n",
              " '▁지루한': 779,\n",
              " '▁옛': 780,\n",
              " '▁흐': 781,\n",
              " '기에': 782,\n",
              " '아니': 783,\n",
              " '에요': 784,\n",
              " '이란': 785,\n",
              " '▁못한': 786,\n",
              " '▁무섭': 787,\n",
              " '▁배경': 788,\n",
              " '▁어린': 789,\n",
              " '▁웃음': 790,\n",
              " '▁만들었': 791,\n",
              " '▁보는내내': 792,\n",
              " '▁날': 793,\n",
              " '럽게': 794,\n",
              " '리지': 795,\n",
              " '보단': 796,\n",
              " '▁당시': 797,\n",
              " '▁제발': 798,\n",
              " '▁좋고': 799,\n",
              " '▁주는': 800,\n",
              " '영화를': 801,\n",
              " '▁영화관': 802,\n",
              " '▁재미가': 803,\n",
              " '▁최고다': 804,\n",
              " '었습니다': 805,\n",
              " '▁또': 806,\n",
              " '▁태': 807,\n",
              " '▁황': 808,\n",
              " '▁희': 809,\n",
              " '기가': 810,\n",
              " '스팅': 811,\n",
              " '없음': 812,\n",
              " '할수': 813,\n",
              " '▁어설': 814,\n",
              " '▁애니메이션': 815,\n",
              " '▁깊': 816,\n",
              " '▁빨': 817,\n",
              " '▁큰': 818,\n",
              " '▁무엇': 819,\n",
              " '▁미친': 820,\n",
              " '▁분위': 821,\n",
              " '▁안타': 822,\n",
              " '▁어릴': 823,\n",
              " '▁없이': 824,\n",
              " '스토리': 825,\n",
              " '▁라': 826,\n",
              " '▁러': 827,\n",
              " '▁산': 828,\n",
              " '▁색': 829,\n",
              " '▁첨': 830,\n",
              " '▁총': 831,\n",
              " '▁확': 832,\n",
              " '나요': 833,\n",
              " '동안': 834,\n",
              " '▁도대체': 835,\n",
              " '▁개인적으로': 836,\n",
              " '난다': 837,\n",
              " '▁인상': 838,\n",
              " '▁추억': 839,\n",
              " '▁보세요': 840,\n",
              " '▁극장에서': 841,\n",
              " '▁모르겠다': 842,\n",
              " '▁갑': 843,\n",
              " '▁궁': 844,\n",
              " '구만': 845,\n",
              " '인줄': 846,\n",
              " '▁강추': 847,\n",
              " '▁주제': 848,\n",
              " '▁행복': 849,\n",
              " '▁보지마': 850,\n",
              " '▁배우들의': 851,\n",
              " '▁팬': 852,\n",
              " '더니': 853,\n",
              " '정이': 854,\n",
              " '학교': 855,\n",
              " '▁귀여': 856,\n",
              " '▁다큐': 857,\n",
              " '▁빠져': 858,\n",
              " '▁힘들': 859,\n",
              " '나리오': 860,\n",
              " '▁로맨스': 861,\n",
              " '▁안되는': 862,\n",
              " '▁이해가': 863,\n",
              " '▁우리나라': 864,\n",
              " '▁깨': 865,\n",
              " '▁싫': 866,\n",
              " '▁양': 867,\n",
              " '거리': 868,\n",
              " '디오': 869,\n",
              " '이네': 870,\n",
              " '있다': 871,\n",
              " '▁봤던': 872,\n",
              " '▁작가': 873,\n",
              " '▁후회': 874,\n",
              " '이지만': 875,\n",
              " '한영화': 876,\n",
              " '▁포스터': 877,\n",
              " '▁한국영화': 878,\n",
              " '▁임': 879,\n",
              " '것이': 880,\n",
              " '▁그렇': 881,\n",
              " '▁누가': 882,\n",
              " '▁살아': 883,\n",
              " '▁엔딩': 884,\n",
              " '▁의미': 885,\n",
              " '▁주연': 886,\n",
              " '▁중국': 887,\n",
              " '▁연기는': 888,\n",
              " '▁재밌어요': 889,\n",
              " '▁왠': 890,\n",
              " '마다': 891,\n",
              " '▁답답': 892,\n",
              " '▁엉성': 893,\n",
              " '▁충분': 894,\n",
              " '▁생각이': 895,\n",
              " '▁물': 896,\n",
              " '▁용': 897,\n",
              " '▁준': 898,\n",
              " '▁청': 899,\n",
              " '감동': 900,\n",
              " '보니': 901,\n",
              " '부분': 902,\n",
              " '아깝': 903,\n",
              " '▁다른': 904,\n",
              " '▁않았': 905,\n",
              " '▁킬링': 906,\n",
              " '▁영화로': 907,\n",
              " '▁식': 908,\n",
              " '▁으': 909,\n",
              " '있고': 910,\n",
              " '점대': 911,\n",
              " '지가': 912,\n",
              " '치고': 913,\n",
              " '한데': 914,\n",
              " '▁안되': 915,\n",
              " '▁오늘': 916,\n",
              " '▁진부': 917,\n",
              " '이네요': 918,\n",
              " '하는데': 919,\n",
              " '▁기억에': 920,\n",
              " '▁이정도': 921,\n",
              " '▁백': 922,\n",
              " '▁브': 923,\n",
              " '▁암': 924,\n",
              " '▁터': 925,\n",
              " '놓고': 926,\n",
              " '성도': 927,\n",
              " '을듯': 928,\n",
              " '▁관객': 929,\n",
              " '▁문제': 930,\n",
              " '▁스타': 931,\n",
              " '▁슬프': 932,\n",
              " '▁신선': 933,\n",
              " '▁실화': 934,\n",
              " '▁어이': 935,\n",
              " '▁없음': 936,\n",
              " '▁초반': 937,\n",
              " '▁영화중': 938,\n",
              " '▁지루함': 939,\n",
              " '▁하나도': 940,\n",
              " '▁좋아하는': 941,\n",
              " '▁꿈': 942,\n",
              " '▁등': 943,\n",
              " '▁변': 944,\n",
              " '▁종': 945,\n",
              " '나게': 946,\n",
              " '인이': 947,\n",
              " '한거': 948,\n",
              " '▁나올': 949,\n",
              " '▁더빙': 950,\n",
              " '▁집중': 951,\n",
              " '▁몰입도': 952,\n",
              " '▁봤어요': 953,\n",
              " '▁시나리오': 954,\n",
              " '▁민': 955,\n",
              " '▁책': 956,\n",
              " '▁함': 957,\n",
              " '당히': 958,\n",
              " '어가': 959,\n",
              " '이버': 960,\n",
              " '좋아': 961,\n",
              " '▁되는': 962,\n",
              " '▁지나': 963,\n",
              " '으로도': 964,\n",
              " '▁재밌는': 965,\n",
              " '▁공포영화': 966,\n",
              " '▁글': 967,\n",
              " '▁낫': 968,\n",
              " '▁패': 969,\n",
              " '▁어색': 970,\n",
              " '▁언제': 971,\n",
              " '▁옛날': 972,\n",
              " '▁감동도': 973,\n",
              " '▁사람들': 974,\n",
              " '▁킬링타임': 975,\n",
              " '▁맘': 976,\n",
              " '▁멜': 977,\n",
              " '▁투': 978,\n",
              " '소리': 979,\n",
              " '작품': 980,\n",
              " '지마': 981,\n",
              " '▁걸작': 982,\n",
              " '▁돌아': 983,\n",
              " '▁예술': 984,\n",
              " '▁완벽': 985,\n",
              " '▁있고': 986,\n",
              " '▁길': 987,\n",
              " '▁범': 988,\n",
              " '▁클': 989,\n",
              " '건가': 990,\n",
              " '나마': 991,\n",
              " '아까': 992,\n",
              " '야지': 993,\n",
              " '해라': 994,\n",
              " '▁부분': 995,\n",
              " '▁순수': 996,\n",
              " '▁역사': 997,\n",
              " '▁졸작': 998,\n",
              " '▁가슴이': 999,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 508
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mecab-python3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_dAmdzELCCE",
        "outputId": "5b167cbe-213b-4b55-d9d7-a8a6dc27895c"
      },
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mecab-python3\n",
            "  Downloading mecab_python3-1.0.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
            "Downloading mecab_python3-1.0.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/588.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m583.7/588.8 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.8/588.8 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mecab-python3\n",
            "Successfully installed mecab-python3-1.0.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from mecab import MeCab\n",
        "mecab = MeCab()"
      ],
      "metadata": {
        "id": "meIRjqk8gSZx"
      },
      "execution_count": 591,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "special_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJQCIrywNFNL",
        "outputId": "3ea1da80-15f8-46ea-afdc-c0f563c822d0"
      },
      "execution_count": 533,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<good>',\n",
              " '<bad>',\n",
              " '<profanity>',\n",
              " '<SadToken>',\n",
              " '<HappyToken>',\n",
              " '<filter>',\n",
              " '<zz>',\n",
              " '<hh>',\n",
              " '<NormalToken>']"
            ]
          },
          "metadata": {},
          "execution_count": 533
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "special_token_map = {token: str(1000 + i) for i, token in enumerate(special_tokens)}\n",
        "reverse_token_map = {v: k for k, v in special_token_map.items()}\n",
        "\n",
        "def preprocess_special_tokens(text, special_token_map):\n",
        "    for token, num in special_token_map.items():\n",
        "        text = text.replace(token, num)\n",
        "    return text\n",
        "\n",
        "def postprocess_special_tokens(tokens, reverse_token_map):\n",
        "    return [reverse_token_map.get(token, token) for token in tokens]\n",
        "\n",
        "def tokenize(text):\n",
        "    if isinstance(text, str):\n",
        "        preprocessed_text = preprocess_special_tokens(text, special_token_map)\n",
        "        tokens = mecab.morphs(preprocessed_text)\n",
        "\n",
        "        final_tokens = postprocess_special_tokens(tokens, reverse_token_map)\n",
        "\n",
        "        return final_tokens\n",
        "    else:\n",
        "        return []"
      ],
      "metadata": {
        "id": "JMRbd13rM8_y"
      },
      "execution_count": 270,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize2(corpus, tokenizer=None, train=True):  # corpus: Tokenized Sentence's List\n",
        "  if train:\n",
        "    tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='',oov_token='<OOV>')\n",
        "    tokenizer.fit_on_texts(corpus)\n",
        "\n",
        "  tensor = tokenizer.texts_to_sequences(corpus)\n",
        "\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "  tensor,\n",
        "  maxlen=max_len,\n",
        "  padding='post',\n",
        "  truncating='post'\n",
        ")\n",
        "\n",
        "  return tensor, tokenizer"
      ],
      "metadata": {
        "id": "61w_a7yKLNH6"
      },
      "execution_count": 312,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ko_token(df):\n",
        "  texts=[]\n",
        "  for i in df['document2']:\n",
        "    texts.append(tokenize(i))\n",
        "  return texts"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Po3QPHaWL_G1"
      },
      "execution_count": 284,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxrCQ9MRQyyf",
        "outputId": "103cf2e5-86e2-48b4-fcd4-14e49a8cfdef"
      },
      "execution_count": 661,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17758"
            ]
          },
          "metadata": {},
          "execution_count": 661
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_list=ko_token(train_df)\n",
        "valid_list=ko_token(valid_df)\n",
        "test_list=ko_token(test_re)"
      ],
      "metadata": {
        "id": "6O_Rhn2IO7BX"
      },
      "execution_count": 659,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_tensor, tokenizer = tokenize2(train_list,None,True)\n",
        "valid_tensor, _ = tokenize2(valid_list,tokenizer,False)\n",
        "test_tensor, _ = tokenize2(test_list,tokenizer,False)"
      ],
      "metadata": {
        "id": "fV7IZatIPBIa"
      },
      "execution_count": 660,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "train_dataset2 = tf.data.Dataset.from_tensor_slices((train_tensor,\n",
        "    train_df['label']\n",
        ")).shuffle(buffer_size=len(train_df),seed=42).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "valid_dataset2 = tf.data.Dataset.from_tensor_slices((valid_tensor,\n",
        "    valid_df['label']\n",
        ")).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "test_dataset2 = tf.data.Dataset.from_tensor_slices((test_tensor, test_re['label'])).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "cKuDF6ZRN0YE"
      },
      "execution_count": 662,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam, AdamW\n",
        "\n",
        "lr = 3e-4\n",
        "\n",
        "vocab_size = 17759\n",
        "embedding_dim = 256\n",
        "lstm_units = 64\n",
        "\n",
        "input_ = Input(shape=(None,), name='input')\n",
        "x = Embedding(input_dim=vocab_size, output_dim=embedding_dim, mask_zero=True)(input_)\n",
        "x = Dropout(0.3)(x)\n",
        "\n",
        "#x = Bidirectional(LSTM(lstm_units, return_sequences=False))(x)\n",
        "#x = Bidirectional(LSTM(lstm_units, return_sequences=False))(x)\n",
        "#x = LSTM(lstm_units, return_sequences=True)(x)\n",
        "x = LSTM(lstm_units, return_sequences=False)(x)\n",
        "\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model2 = Model(inputs=input_, outputs=output)\n",
        "\n",
        "model2.compile(optimizer=AdamW(learning_rate=lr,weight_decay=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "id": "o6KJrbz0NRFT",
        "outputId": "2cffbc28-e9ce-4084-b568-74f90e909dfb"
      },
      "execution_count": 663,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_62\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_62\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_64        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m4,546,304\u001b[0m │ input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_174         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ embedding_64[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal_62        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_84 (\u001b[38;5;33mLSTM\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m82,176\u001b[0m │ dropout_174[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ not_equal_62[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_175         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ lstm_84[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_125 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m4,160\u001b[0m │ dropout_175[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_176         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_125[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_126 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dropout_176[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_64        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,546,304</span> │ input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_174         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_64[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal_62        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_84 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">82,176</span> │ dropout_174[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ not_equal_62[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_175         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_84[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_125 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ dropout_175[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_176         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_125[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_126 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dropout_176[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,632,705\u001b[0m (17.67 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,632,705</span> (17.67 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,632,705\u001b[0m (17.67 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,632,705</span> (17.67 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True, verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1)"
      ],
      "metadata": {
        "id": "F6pIVxicQkTi"
      },
      "execution_count": 664,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history2 = model2.fit(\n",
        "    train_dataset2,\n",
        "    validation_data=valid_dataset2,\n",
        "    epochs=20,\n",
        "    callbacks=[early_stop, reduce_lr]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaAX_VnDQnZh",
        "outputId": "407002be-3903-4d64-f7f8-e2ca81c17058"
      },
      "execution_count": 665,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.5904 - loss: 0.6590 - val_accuracy: 0.8160 - val_loss: 0.4142 - learning_rate: 3.0000e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8453 - loss: 0.3779 - val_accuracy: 0.8384 - val_loss: 0.3706 - learning_rate: 3.0000e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.8987 - loss: 0.2700 - val_accuracy: 0.8346 - val_loss: 0.3837 - learning_rate: 3.0000e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m144/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9250 - loss: 0.2108\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9249 - loss: 0.2109 - val_accuracy: 0.8324 - val_loss: 0.4066 - learning_rate: 3.0000e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.9449 - loss: 0.1653 - val_accuracy: 0.8270 - val_loss: 0.4617 - learning_rate: 1.5000e-04\n",
            "Epoch 5: early stopping\n",
            "Restoring model weights from the end of the best epoch: 2.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.evaluate(test_dataset2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYs4RAHHSYnj",
        "outputId": "4f19fbd6-12a2-498e-a6f7-6a73eca52654"
      },
      "execution_count": 666,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8277 - loss: 0.3814\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.38503676652908325, 0.8279653191566467]"
            ]
          },
          "metadata": {},
          "execution_count": 666
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.evaluate(test_dataset2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dW9FUJUt2-WG",
        "outputId": "9ca1aff6-dc94-40b0-b6bf-fa2949a111ab"
      },
      "execution_count": 599,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8347 - loss: 0.3812\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3832939565181732, 0.8308586478233337]"
            ]
          },
          "metadata": {},
          "execution_count": 599
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index['<OOV>']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfOHCkfISsel",
        "outputId": "53715d34-81b1-403e-f47b-a4d49d221190"
      },
      "execution_count": 319,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 319
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_oov_count = np.sum(valid_tensor == 1)\n",
        "test_oov_count = np.sum(test_tensor == 1)\n",
        "\n",
        "# 전체 token 개수 (option 1: 모든 token 기준)\n",
        "valid_total_tokens = np.prod(valid_tensor.shape)\n",
        "test_total_tokens = np.prod(test_tensor.shape)\n",
        "\n",
        "# 또는 샘플 수 기준으로 정규화 (option 2: 샘플 기준)\n",
        "valid_sample_count = valid_tensor.shape[0]\n",
        "test_sample_count = test_tensor.shape[0]\n",
        "\n",
        "# 비율 계산\n",
        "valid_oov_ratio = valid_oov_count / valid_total_tokens\n",
        "test_oov_ratio = test_oov_count / test_total_tokens\n",
        "\n",
        "valid_oov_per_sample = valid_oov_count / valid_sample_count\n",
        "test_oov_per_sample = test_oov_count / test_sample_count\n",
        "\n",
        "print(f\"✅ Validation OOV count: {valid_oov_count}\")\n",
        "print(f\"✅ Validation OOV ratio (tokens): {valid_oov_ratio:.4f}\")\n",
        "print(f\"✅ Validation OOV per sample: {valid_oov_per_sample:.2f}\")\n",
        "\n",
        "print(f\"✅ Test OOV count: {test_oov_count}\")\n",
        "print(f\"✅ Test OOV ratio (tokens): {test_oov_ratio:.4f}\")\n",
        "print(f\"✅ Test OOV per sample: {test_oov_per_sample:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4YXa37GTB87",
        "outputId": "8b5965f2-334c-48ea-8d4e-a235147298fd"
      },
      "execution_count": 517,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Validation OOV count: 2407\n",
            "✅ Validation OOV ratio (tokens): 0.0049\n",
            "✅ Validation OOV per sample: 0.49\n",
            "✅ Test OOV count: 3896\n",
            "✅ Test OOV ratio (tokens): 0.0047\n",
            "✅ Test OOV per sample: 0.47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3.fasttext"
      ],
      "metadata": {
        "id": "JhRt7Y3ZkueR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ko.300.bin.gz\n",
        "!gunzip cc.ko.300.bin.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7L5wf7aIkwU6",
        "outputId": "fe20a5c7-dfd7-4901-fe91-0b72590ced1f"
      },
      "execution_count": 518,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-09 05:44:44--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ko.300.bin.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 13.227.219.33, 13.227.219.70, 13.227.219.10, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|13.227.219.33|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4486458164 (4.2G) [application/octet-stream]\n",
            "Saving to: ‘cc.ko.300.bin.gz’\n",
            "\n",
            "cc.ko.300.bin.gz    100%[===================>]   4.18G  25.5MB/s    in 5m 43s  \n",
            "\n",
            "2025-05-09 05:50:28 (12.5 MB/s) - ‘cc.ko.300.bin.gz’ saved [4486458164/4486458164]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fasttext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezre0my-lOT7",
        "outputId": "48c927ed-61e9-4f28-9854-2665086e32ce"
      },
      "execution_count": 521,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.3.tar.gz (73 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/73.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.4/73.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11>=2.2 (from fasttext)\n",
            "  Using cached pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from fasttext) (75.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fasttext) (1.26.4)\n",
            "Using cached pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.3-cp311-cp311-linux_x86_64.whl size=4313505 sha256=cee03c91ec60ae8779ab5c3c88b3fe5e5d0c29478177cd80a8bf6c43638fb792\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/4f/35/5057db0249224e9ab55a513fa6b79451473ceb7713017823c3\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.3 pybind11-2.13.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fasttext\n",
        "\n",
        "# binary 모델 로드\n",
        "fasttext_model = fasttext.load_model('cc.ko.300.bin')"
      ],
      "metadata": {
        "id": "1PG4DC14k1X0"
      },
      "execution_count": 522,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_mecab=tokenizer.word_index.keys()"
      ],
      "metadata": {
        "id": "2VvC8TI6n7su"
      },
      "execution_count": 525,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_tokens = ['<PAD>'] + list(tokenizer.word_index.keys())"
      ],
      "metadata": {
        "id": "SAdEHMLxo0Fz"
      },
      "execution_count": 528,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index['<OOV>']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuEVgOdFoRS9",
        "outputId": "1445c073-094a-4c7a-ab8d-2c56a29292a8"
      },
      "execution_count": 527,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 527
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = fasttext_model.get_dimension()  # fastText vector dimension\n",
        "vocab_size = len(vocab_tokens)\n",
        "\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "\n",
        "for i, token in enumerate(vocab_tokens):\n",
        "    if token == '<PAD>':\n",
        "        embedding_matrix[i] = np.zeros(embedding_dim)  # padding은 zero vector\n",
        "    elif token == '<OOV>':\n",
        "        embedding_matrix[i] = np.random.normal(0, 1, embedding_dim)  # oov는 random init or 지정\n",
        "    else:\n",
        "        embedding_matrix[i] = fasttext_model.get_word_vector(token)"
      ],
      "metadata": {
        "id": "MBCgmW8tn47B"
      },
      "execution_count": 530,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RofTt-aApJlm",
        "outputId": "978b14b9-d0e7-45da-c5e4-f468cca4f882"
      },
      "execution_count": 532,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18015, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 532
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "lr = 2e-4\n",
        "\n",
        "vocab_size = 18015\n",
        "lstm_units = 64\n",
        "\n",
        "input_ = Input(shape=(None,), name='input')\n",
        "embedding_layer = Embedding(\n",
        "    input_dim=embedding_matrix.shape[0],\n",
        "    output_dim=embedding_matrix.shape[1],\n",
        "    weights=[embedding_matrix],\n",
        "    trainable=True,\n",
        "    mask_zero=True\n",
        ")\n",
        "\n",
        "x = embedding_layer(input_)\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "# x = LSTM(lstm_units, return_sequences=True)(x)\n",
        "# x = LSTM(lstm_units, return_sequences=False)(x)\n",
        "\n",
        "#x = Bidirectional(LSTM(lstm_units, return_sequences=True))(x)\n",
        "x = Bidirectional(LSTM(lstm_units, return_sequences=False))(x)\n",
        "\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model3 = Model(inputs=input_, outputs=output)\n",
        "\n",
        "model3.compile(optimizer=Adam(learning_rate=lr), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "id": "T-UJIEaapeqe",
        "outputId": "3b9982ed-0da2-43f4-faa6-dce1eafc67a9"
      },
      "execution_count": 563,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_46\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_46\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_48        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m) │  \u001b[38;5;34m5,404,500\u001b[0m │ input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_126         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ embedding_48[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal_46        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_61    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │    \u001b[38;5;34m186,880\u001b[0m │ dropout_126[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │ not_equal_46[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_127         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ bidirectional_61… │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_93 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m16,512\u001b[0m │ dropout_127[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_128         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_93[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_94 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m129\u001b[0m │ dropout_128[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_48        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">5,404,500</span> │ input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_126         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_48[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal_46        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_61    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">186,880</span> │ dropout_126[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │ not_equal_46[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_127         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_61… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_93 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ dropout_127[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_128         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_93[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_94 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dropout_128[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,608,021\u001b[0m (21.39 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,608,021</span> (21.39 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,608,021\u001b[0m (21.39 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,608,021</span> (21.39 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True, verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1)"
      ],
      "metadata": {
        "id": "GIPRAFl0qDWb"
      },
      "execution_count": 564,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history3 = model3.fit(\n",
        "    train_dataset2,\n",
        "    validation_data=valid_dataset2,\n",
        "    epochs=20,\n",
        "    callbacks=[early_stop, reduce_lr]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOyNcIQfqGOX",
        "outputId": "2f87e401-ef00-4c86-c245-6283ade96f0f"
      },
      "execution_count": 565,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.6014 - loss: 0.6637 - val_accuracy: 0.7865 - val_loss: 0.4632 - learning_rate: 2.0000e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.8086 - loss: 0.4266 - val_accuracy: 0.8224 - val_loss: 0.3957 - learning_rate: 2.0000e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.8551 - loss: 0.3479 - val_accuracy: 0.8283 - val_loss: 0.3793 - learning_rate: 2.0000e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.8767 - loss: 0.3041 - val_accuracy: 0.8236 - val_loss: 0.3864 - learning_rate: 2.0000e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8932 - loss: 0.2718\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-05.\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.8932 - loss: 0.2717 - val_accuracy: 0.8254 - val_loss: 0.3895 - learning_rate: 2.0000e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9141 - loss: 0.2343 - val_accuracy: 0.8240 - val_loss: 0.4056 - learning_rate: 1.0000e-04\n",
            "Epoch 6: early stopping\n",
            "Restoring model weights from the end of the best epoch: 3.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model3.evaluate(test_dataset2) # embedding trainable false"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9VAxpvOqJcp",
        "outputId": "b849fc12-e5c1-468b-b5a5-797979c7a045"
      },
      "execution_count": 538,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7713 - loss: 0.4761\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.47900551557540894, 0.7685859799385071]"
            ]
          },
          "metadata": {},
          "execution_count": 538
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model3.evaluate(test_dataset2) # embedding trainable true, 성능차이 크지 않음"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Azn4aG7rVCq",
        "outputId": "de49a1d7-9945-47b1-fe91-0f5976902c19"
      },
      "execution_count": 566,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8248 - loss: 0.3883\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3947245478630066, 0.8219144940376282]"
            ]
          },
          "metadata": {},
          "execution_count": 566
        }
      ]
    }
  ]
}